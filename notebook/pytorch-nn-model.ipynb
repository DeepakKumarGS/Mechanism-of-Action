{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02764,
     "end_time": "2020-11-02T01:22:11.361175",
     "exception": false,
     "start_time": "2020-11-02T01:22:11.333535",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Reference :\n",
    "\n",
    "https://www.kaggle.com/yasufuminakama/moa-pytorch-nn-starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:11.422749Z",
     "iopub.status.busy": "2020-11-02T01:22:11.421732Z",
     "iopub.status.idle": "2020-11-02T01:22:12.364652Z",
     "shell.execute_reply": "2020-11-02T01:22:12.363258Z"
    },
    "papermill": {
     "duration": 0.97517,
     "end_time": "2020-11-02T01:22:12.364794",
     "exception": false,
     "start_time": "2020-11-02T01:22:11.389624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:12.433989Z",
     "iopub.status.busy": "2020-11-02T01:22:12.433014Z",
     "iopub.status.idle": "2020-11-02T01:22:12.444504Z",
     "shell.execute_reply": "2020-11-02T01:22:12.445037Z"
    },
    "papermill": {
     "duration": 0.050858,
     "end_time": "2020-11-02T01:22:12.445196",
     "exception": false,
     "start_time": "2020-11-02T01:22:12.394338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/lish-moa/sample_submission.csv\n",
      "/kaggle/input/lish-moa/train_targets_scored.csv\n",
      "/kaggle/input/lish-moa/train_targets_nonscored.csv\n",
      "/kaggle/input/lish-moa/train_features.csv\n",
      "/kaggle/input/lish-moa/test_features.csv\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/.gitignore\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/LICENSE\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/setup.cfg\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/.travis.yml\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/README.md\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/setup.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/tests/test_ml_stratifiers.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/tests/__init__.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/iterstrat/ml_stratifiers.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/iterstrat/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:12.507295Z",
     "iopub.status.busy": "2020-11-02T01:22:12.506337Z",
     "iopub.status.idle": "2020-11-02T01:22:12.511768Z",
     "shell.execute_reply": "2020-11-02T01:22:12.511160Z"
    },
    "papermill": {
     "duration": 0.03819,
     "end_time": "2020-11-02T01:22:12.511884",
     "exception": false,
     "start_time": "2020-11-02T01:22:12.473694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/__notebook__.ipynb\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/working'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:12.573156Z",
     "iopub.status.busy": "2020-11-02T01:22:12.572524Z",
     "iopub.status.idle": "2020-11-02T01:22:14.076727Z",
     "shell.execute_reply": "2020-11-02T01:22:14.075232Z"
    },
    "papermill": {
     "duration": 1.536668,
     "end_time": "2020-11-02T01:22:14.076858",
     "exception": false,
     "start_time": "2020-11-02T01:22:12.540190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:14.154166Z",
     "iopub.status.busy": "2020-11-02T01:22:14.153179Z",
     "iopub.status.idle": "2020-11-02T01:22:20.439675Z",
     "shell.execute_reply": "2020-11-02T01:22:20.438111Z"
    },
    "papermill": {
     "duration": 6.333536,
     "end_time": "2020-11-02T01:22:20.439805",
     "exception": false,
     "start_time": "2020-11-02T01:22:14.106269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features=pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "test_features=pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "train_targets_scored=pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "sample_submission=pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:20.506471Z",
     "iopub.status.busy": "2020-11-02T01:22:20.505658Z",
     "iopub.status.idle": "2020-11-02T01:22:20.536037Z",
     "shell.execute_reply": "2020-11-02T01:22:20.535468Z"
    },
    "papermill": {
     "duration": 0.067155,
     "end_time": "2020-11-02T01:22:20.536146",
     "exception": false,
     "start_time": "2020-11-02T01:22:20.468991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr_ctrl_vehicle_idx=train_features[train_features['cp_type']=='ctl_vehicle']['sig_id'].values\n",
    "te_ctrl_vehicle_idx=test_features[test_features['cp_type']=='ctl_vehicle']['sig_id'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:20.602041Z",
     "iopub.status.busy": "2020-11-02T01:22:20.600922Z",
     "iopub.status.idle": "2020-11-02T01:22:20.692778Z",
     "shell.execute_reply": "2020-11-02T01:22:20.692128Z"
    },
    "papermill": {
     "duration": 0.128634,
     "end_time": "2020-11-02T01:22:20.692899",
     "exception": false,
     "start_time": "2020-11-02T01:22:20.564265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features=train_features[~train_features['sig_id'].isin(tr_ctrl_vehicle_idx)]\n",
    "test_features=test_features[~test_features['sig_id'].isin(te_ctrl_vehicle_idx)]\n",
    "train_targets_scored=train_targets_scored[~train_targets_scored['sig_id'].isin(tr_ctrl_vehicle_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:21.120984Z",
     "iopub.status.busy": "2020-11-02T01:22:21.119967Z",
     "iopub.status.idle": "2020-11-02T01:22:21.122534Z",
     "shell.execute_reply": "2020-11-02T01:22:21.123088Z"
    },
    "papermill": {
     "duration": 0.400702,
     "end_time": "2020-11-02T01:22:21.123237",
     "exception": false,
     "start_time": "2020-11-02T01:22:20.722535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:21.205486Z",
     "iopub.status.busy": "2020-11-02T01:22:21.190431Z",
     "iopub.status.idle": "2020-11-02T01:22:21.224426Z",
     "shell.execute_reply": "2020-11-02T01:22:21.225063Z"
    },
    "papermill": {
     "duration": 0.070757,
     "end_time": "2020-11-02T01:22:21.225215",
     "exception": false,
     "start_time": "2020-11-02T01:22:21.154458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_000644bb2  trt_cp       24      D1  1.0620  0.5577 -0.2479 -0.6208   \n",
       "1  id_000779bfc  trt_cp       72      D1  0.0743  0.4087  0.2991  0.0604   \n",
       "2  id_000a6266a  trt_cp       48      D1  0.6280  0.5817  1.5540 -0.0764   \n",
       "3  id_0015fd391  trt_cp       48      D1 -0.5138 -0.2491 -0.2656  0.5288   \n",
       "4  id_001626bd3  trt_cp       72      D2 -0.3254 -0.4009  0.9700  0.6919   \n",
       "\n",
       "      g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0 -0.1944 -1.0120  ...  0.2862  0.2584  0.8076  0.5523 -0.1912  0.6584   \n",
       "1  1.0190  0.5207  ... -0.4265  0.7543  0.4708  0.0230  0.2957  0.4899   \n",
       "2 -0.0323  1.2390  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240 -0.3174   \n",
       "3  4.0620 -0.8095  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632 -1.2880   \n",
       "4  1.4180 -0.8244  ...  0.0042  0.0048  0.6670  1.0690  0.5523 -0.3031   \n",
       "\n",
       "     c-96    c-97    c-98    c-99  \n",
       "0 -0.3981  0.2139  0.3801  0.4176  \n",
       "1  0.1522  0.1241  0.6077  0.7371  \n",
       "2 -0.6417 -0.2187 -1.4080  0.6931  \n",
       "3 -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "4  0.1094  0.2885 -0.3786  0.7125  \n",
       "\n",
       "[5 rows x 876 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:21.295712Z",
     "iopub.status.busy": "2020-11-02T01:22:21.294837Z",
     "iopub.status.idle": "2020-11-02T01:22:23.305909Z",
     "shell.execute_reply": "2020-11-02T01:22:23.305291Z"
    },
    "papermill": {
     "duration": 2.049017,
     "end_time": "2020-11-02T01:22:23.306033",
     "exception": false,
     "start_time": "2020-11-02T01:22:21.257016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing g-0 with mean 0.27767496810643344 and std 1.4271207461708488\n",
      "Standardizing g-1 with mean -0.07984522963368006 and std 0.8019541944616344\n",
      "Standardizing g-2 with mean 0.16839111536358686 and std 1.0357960655603637\n",
      "Standardizing g-3 with mean 0.08126479861490798 and std 0.9551166268562821\n",
      "Standardizing g-4 with mean 0.08497379715691607 and std 1.023297028140235\n",
      "Standardizing g-5 with mean -0.14338197102241745 and std 1.183272373245025\n",
      "Standardizing g-6 with mean 0.012125505740841893 and std 0.8710035960674436\n",
      "Standardizing g-7 with mean -0.20433155640605224 and std 1.1368235963422506\n",
      "Standardizing g-8 with mean -0.23986487151448976 and std 1.8001942558970068\n",
      "Standardizing g-9 with mean 0.10428110989611707 and std 1.1014531104483078\n",
      "Standardizing g-10 with mean -0.13397369691999195 and std 1.3136343644444792\n",
      "Standardizing g-11 with mean 0.2028165071988361 and std 1.2778977148493642\n",
      "Standardizing g-12 with mean 0.1076905139420456 and std 1.2315789848943517\n",
      "Standardizing g-13 with mean 0.21353206670311647 and std 1.3028426562716746\n",
      "Standardizing g-14 with mean -0.190993461818844 and std 1.270448039059614\n",
      "Standardizing g-15 with mean -0.018575997813012515 and std 0.6609897451882172\n",
      "Standardizing g-16 with mean 0.10361789229086964 and std 1.4454264513198363\n",
      "Standardizing g-17 with mean -0.1758049845088385 and std 1.1968958112005408\n",
      "Standardizing g-18 with mean 0.09816384636413356 and std 0.7525619215867245\n",
      "Standardizing g-19 with mean -0.07409103790778228 and std 0.8439389249521557\n",
      "Standardizing g-20 with mean -0.14439561691270303 and std 1.2365320397764945\n",
      "Standardizing g-21 with mean -0.07485267450337145 and std 0.8056819745784397\n",
      "Standardizing g-22 with mean 0.0722207763805353 and std 0.9380324905817866\n",
      "Standardizing g-23 with mean -0.11586708583925649 and std 0.7599373805724805\n",
      "Standardizing g-24 with mean -0.1270383998542006 and std 1.2198833419141903\n",
      "Standardizing g-25 with mean -0.07764182613449931 and std 0.8737006874778149\n",
      "Standardizing g-26 with mean -0.1356502460360846 and std 1.1052298994613552\n",
      "Standardizing g-27 with mean 0.14702066703116334 and std 0.9922927213157918\n",
      "Standardizing g-28 with mean -0.08689747129579051 and std 1.0390575392114787\n",
      "Standardizing g-29 with mean -0.07287005194095172 and std 1.307488375187006\n",
      "Standardizing g-30 with mean -0.21744441862584335 and std 1.3358042144359925\n",
      "Standardizing g-31 with mean 0.40218018042646325 and std 1.5996574581800742\n",
      "Standardizing g-32 with mean -0.18896428376161817 and std 0.9396347517162627\n",
      "Standardizing g-33 with mean 0.04960233734281061 and std 1.185436931258284\n",
      "Standardizing g-34 with mean -0.07124776745033683 and std 1.196666610260552\n",
      "Standardizing g-35 with mean 0.1338225943138327 and std 1.0736106767382758\n",
      "Standardizing g-36 with mean -0.1976552578822678 and std 1.4268486381769818\n",
      "Standardizing g-37 with mean -0.6638323400765439 and std 2.267767199192367\n",
      "Standardizing g-38 with mean 0.5913689128850015 and std 2.0559114382405124\n",
      "Standardizing g-39 with mean 0.18245616001458043 and std 0.9915838362002791\n",
      "Standardizing g-40 with mean -0.22299998633133125 and std 1.2864480264766691\n",
      "Standardizing g-41 with mean -0.1582762529615461 and std 1.2810734198994487\n",
      "Standardizing g-42 with mean -0.11130755877528611 and std 1.0107629557754123\n",
      "Standardizing g-43 with mean 0.027456278476398928 and std 0.9067356756387964\n",
      "Standardizing g-44 with mean -0.02531128121013325 and std 0.9993598840538159\n",
      "Standardizing g-45 with mean -0.1570191999271011 and std 1.1327126672513461\n",
      "Standardizing g-46 with mean 0.21563232640787336 and std 1.1661270502895986\n",
      "Standardizing g-47 with mean 0.056124211773282355 and std 1.0776076191545634\n",
      "Standardizing g-48 with mean 0.20019646892655327 and std 1.415147114809718\n",
      "Standardizing g-49 with mean -0.024522170585019203 and std 0.9818469232924105\n",
      "Standardizing g-50 with mean -0.6696222571532742 and std 2.3209275424418454\n",
      "Standardizing g-51 with mean 0.0444894979041371 and std 1.0487732855129286\n",
      "Standardizing g-52 with mean -0.04788487789320189 and std 1.0008986381956027\n",
      "Standardizing g-53 with mean 0.1717209859668317 and std 1.238776075716006\n",
      "Standardizing g-54 with mean 0.274015126663021 and std 1.1295562271401143\n",
      "Standardizing g-55 with mean -0.23115112538727914 and std 1.262744467576176\n",
      "Standardizing g-56 with mean -0.15212396573719647 and std 1.2320046848039046\n",
      "Standardizing g-57 with mean -0.006451886276653909 and std 1.2244528701142392\n",
      "Standardizing g-58 with mean -0.4926454847822101 and std 1.929764021920317\n",
      "Standardizing g-59 with mean -0.23406729542555213 and std 1.4039767982058748\n",
      "Standardizing g-60 with mean -0.00028519227264442985 and std 1.0062299755935957\n",
      "Standardizing g-61 with mean -0.2549670767268084 and std 1.2046265266158966\n",
      "Standardizing g-62 with mean -0.23338015764534473 and std 1.7760054098028553\n",
      "Standardizing g-63 with mean -0.4081104702022946 and std 1.8125327568854015\n",
      "Standardizing g-64 with mean -0.04819071897211596 and std 0.9084713331763158\n",
      "Standardizing g-65 with mean 0.33431727264443195 and std 1.464260946505302\n",
      "Standardizing g-66 with mean 0.017654811372334673 and std 0.9399333735948346\n",
      "Standardizing g-67 with mean -0.5254079232731929 and std 2.0764763071875825\n",
      "Standardizing g-68 with mean 0.19790229178057214 and std 1.264725148831395\n",
      "Standardizing g-69 with mean 0.4008830554036815 and std 1.231754582297729\n",
      "Standardizing g-70 with mean -0.01869531164570801 and std 1.1343891053962383\n",
      "Standardizing g-71 with mean -0.13105842445780985 and std 0.8970078433658962\n",
      "Standardizing g-72 with mean -0.45913700109349215 and std 2.0336244608787752\n",
      "Standardizing g-73 with mean -0.060850246036085104 and std 0.8958838318131883\n",
      "Standardizing g-74 with mean 0.29632294058684217 and std 1.4581399594688103\n",
      "Standardizing g-75 with mean -0.5254697193366131 and std 2.313425349696178\n",
      "Standardizing g-76 with mean -0.029166912702751714 and std 0.9086039582969287\n",
      "Standardizing g-77 with mean -0.06829436850738124 and std 0.8650564620205092\n",
      "Standardizing g-78 with mean 0.004636303991252044 and std 0.853087840869797\n",
      "Standardizing g-79 with mean -0.010477387461272133 and std 1.065174229507791\n",
      "Standardizing g-80 with mean -0.1151212228904683 and std 1.088247831391621\n",
      "Standardizing g-81 with mean 0.028944236376890548 and std 1.0059237659139462\n",
      "Standardizing g-82 with mean 0.22699390832877764 and std 1.0879041653683146\n",
      "Standardizing g-83 with mean 0.2860065746309438 and std 1.349325844996946\n",
      "Standardizing g-84 with mean 0.26354457809367626 and std 1.1949965381508076\n",
      "Standardizing g-85 with mean 0.049429246400583396 and std 1.0703682623594637\n",
      "Standardizing g-86 with mean 0.35693544742117783 and std 1.5439237510001727\n",
      "Standardizing g-87 with mean -0.09728889192637147 and std 0.9090113527569446\n",
      "Standardizing g-88 with mean 0.10326133132859473 and std 1.0119083794129076\n",
      "Standardizing g-89 with mean 0.013484672863130922 and std 0.9246945987660473\n",
      "Standardizing g-90 with mean 0.22446539092400142 and std 1.3494691711372169\n",
      "Standardizing g-91 with mean 0.4640560415527568 and std 1.9582606884195979\n",
      "Standardizing g-92 with mean 0.07460795061053425 and std 1.1716973792652943\n",
      "Standardizing g-93 with mean 0.10089735283397162 and std 1.090181499413669\n",
      "Standardizing g-94 with mean -0.006489338436303983 and std 0.8326723740873364\n",
      "Standardizing g-95 with mean 0.22724140240568805 and std 1.344086884270041\n",
      "Standardizing g-96 with mean -0.45187633952980033 and std 1.6604329888602718\n",
      "Standardizing g-97 with mean 0.20657509112447708 and std 1.2847589896356075\n",
      "Standardizing g-98 with mean -0.2960230180426477 and std 1.5316713974855045\n",
      "Standardizing g-99 with mean -0.03202904137051188 and std 0.9262362454784947\n",
      "Standardizing g-100 with mean 0.6428813377073074 and std 2.2022912707337086\n",
      "Standardizing g-101 with mean 0.13884994532531345 and std 1.0320379775086257\n",
      "Standardizing g-102 with mean 0.2195557271733189 and std 1.5102737890549378\n",
      "Standardizing g-103 with mean 0.05762558775287039 and std 1.1093760260818588\n",
      "Standardizing g-104 with mean 0.07711466192819333 and std 0.6206562066659879\n",
      "Standardizing g-105 with mean 0.12455227355567672 and std 1.1513251708522507\n",
      "Standardizing g-106 with mean 0.3761856433387993 and std 1.6106513849064326\n",
      "Standardizing g-107 with mean 0.0013289821396026923 and std 1.3288248740715873\n",
      "Standardizing g-108 with mean -0.12411306269363973 and std 1.1235931651837892\n",
      "Standardizing g-109 with mean -0.07464937579733906 and std 1.0065270153315442\n",
      "Standardizing g-110 with mean -0.12318977583378925 and std 0.9033477860451989\n",
      "Standardizing g-111 with mean 0.1895882130490249 and std 1.007530479082696\n",
      "Standardizing g-112 with mean -0.15417228904683838 and std 1.0941392433067454\n",
      "Standardizing g-113 with mean -0.5454927829414964 and std 1.8839077292018287\n",
      "Standardizing g-114 with mean -0.04626392381993794 and std 1.21595068193916\n",
      "Standardizing g-115 with mean -0.037470612356479215 and std 1.0159650086328493\n",
      "Standardizing g-116 with mean 0.18458000728995827 and std 1.224952645845196\n",
      "Standardizing g-117 with mean -0.0002680198651357825 and std 1.1827736732088527\n",
      "Standardizing g-118 with mean 0.11745623747038464 and std 1.0462279245145323\n",
      "Standardizing g-119 with mean -0.03098422635319858 and std 0.9043918744134579\n",
      "Standardizing g-120 with mean -0.10880639238199388 and std 0.9883528330365289\n",
      "Standardizing g-121 with mean -0.39684522052123 and std 1.6957572847781421\n",
      "Standardizing g-122 with mean 0.046327697284490564 and std 0.901282592605843\n",
      "Standardizing g-123 with mean 0.44736961454346813 and std 1.8330484111849288\n",
      "Standardizing g-124 with mean 0.06910471113541089 and std 0.924468005724325\n",
      "Standardizing g-125 with mean -0.11367061691270387 and std 1.0826070516135762\n",
      "Standardizing g-126 with mean 0.22474892017495776 and std 1.3934445199371288\n",
      "Standardizing g-127 with mean 0.04544143429925282 and std 0.9172904472929653\n",
      "Standardizing g-128 with mean -0.27136436121742474 and std 1.7469989616982997\n",
      "Standardizing g-129 with mean 0.01188500091124473 and std 1.0391769160712074\n",
      "Standardizing g-130 with mean 0.2450314470566796 and std 1.4478152981255838\n",
      "Standardizing g-131 with mean 0.4247450883907426 and std 2.1394258074149572\n",
      "Standardizing g-132 with mean 0.22613308729724746 and std 1.1770962048453915\n",
      "Standardizing g-133 with mean 0.04657546473482786 and std 1.5294593611582583\n",
      "Standardizing g-134 with mean -0.13152035265172168 and std 1.2611771658243607\n",
      "Standardizing g-135 with mean 0.21239997266265861 and std 1.091885992570586\n",
      "Standardizing g-136 with mean -0.03929669673774379 and std 1.144153696442921\n",
      "Standardizing g-137 with mean -0.06651164115181363 and std 1.1185481984890835\n",
      "Standardizing g-138 with mean -0.12935906688536505 and std 1.295742703740761\n",
      "Standardizing g-139 with mean 0.1870126617459464 and std 1.2908749449324228\n",
      "Standardizing g-140 with mean 0.17834945325314353 and std 1.1480818744611716\n",
      "Standardizing g-141 with mean -0.1309065518498277 and std 1.089531914818732\n",
      "Standardizing g-142 with mean 0.23443750227811172 and std 1.4075291144838373\n",
      "Standardizing g-143 with mean 0.28610949061417873 and std 1.1972751326127091\n",
      "Standardizing g-144 with mean 0.30517022507745784 and std 1.4921904605052776\n",
      "Standardizing g-145 with mean 0.3997112265354469 and std 1.290417943967094\n",
      "Standardizing g-146 with mean 0.33419836887187954 and std 1.5581432897257323\n",
      "Standardizing g-147 with mean 0.3666483415345364 and std 1.6841752105261423\n",
      "Standardizing g-148 with mean 0.30914081009659056 and std 1.4015068358409253\n",
      "Standardizing g-149 with mean 0.03145639238199401 and std 0.9559197750057339\n",
      "Standardizing g-150 with mean -0.09951451157280872 and std 0.9141898111004233\n",
      "Standardizing g-151 with mean -0.19099513850920327 and std 0.8879388572655732\n",
      "Standardizing g-152 with mean -0.40607612083105316 and std 1.6529214888608776\n",
      "Standardizing g-153 with mean -0.1433775287042091 and std 0.764316360048854\n",
      "Standardizing g-154 with mean 0.09156489885183144 and std 1.1139225603742338\n",
      "Standardizing g-155 with mean 0.2934462593402583 and std 1.3521156623029404\n",
      "Standardizing g-156 with mean -0.1924996673956615 and std 1.3607712244704708\n",
      "Standardizing g-157 with mean 0.0989462365591397 and std 1.4437698631458227\n",
      "Standardizing g-158 with mean 0.5358598551120833 and std 2.0045770830926792\n",
      "Standardizing g-159 with mean 0.23924060051029775 and std 1.0247390646006196\n",
      "Standardizing g-160 with mean -0.10480134408602128 and std 1.6645707196855002\n",
      "Standardizing g-161 with mean -0.0593935392746493 and std 1.3513343048575834\n",
      "Standardizing g-162 with mean 0.2132602287224362 and std 1.279045389632033\n",
      "Standardizing g-163 with mean 0.3748753280481153 and std 1.5829057913420999\n",
      "Standardizing g-164 with mean 0.1242852378348826 and std 1.3746936454649543\n",
      "Standardizing g-165 with mean -0.15436042464005878 and std 1.0197369594898669\n",
      "Standardizing g-166 with mean -0.054260137597958974 and std 1.2468737977827333\n",
      "Standardizing g-167 with mean -0.03169110169491551 and std 1.3134083360676958\n",
      "Standardizing g-168 with mean -0.012015855658829941 and std 1.1765141698937305\n",
      "Standardizing g-169 with mean 0.031097758337889806 and std 1.0946411412213553\n",
      "Standardizing g-170 with mean 0.3358874567158752 and std 1.6941805984503913\n",
      "Standardizing g-171 with mean 0.08448754784035006 and std 0.9423517608551504\n",
      "Standardizing g-172 with mean -0.1574434845999635 and std 1.1010974459831204\n",
      "Standardizing g-173 with mean 0.06913599872425717 and std 1.1791240937313958\n",
      "Standardizing g-174 with mean 0.2353269591762333 and std 1.2634262975141803\n",
      "Standardizing g-175 with mean -0.022260652451248458 and std 1.670862395717022\n",
      "Standardizing g-176 with mean -0.07454286495352641 and std 1.1220290719345944\n",
      "Standardizing g-177 with mean 0.23257486331328586 and std 1.290923537887747\n",
      "Standardizing g-178 with mean -0.14236843448150177 and std 2.0547540368337596\n",
      "Standardizing g-179 with mean -0.10086245671587452 and std 0.9255663190064385\n",
      "Standardizing g-180 with mean 0.2315131128121015 and std 1.1354429797087076\n",
      "Standardizing g-181 with mean 0.3545951704027717 and std 1.5358846643808919\n",
      "Standardizing g-182 with mean 0.25865991889921497 and std 1.2042180486892404\n",
      "Standardizing g-183 with mean -0.21896950063787188 and std 1.5253646867338624\n",
      "Standardizing g-184 with mean -0.03845624658283196 and std 0.7330944813528113\n",
      "Standardizing g-185 with mean -0.4893217422999848 and std 1.8655995788515103\n",
      "Standardizing g-186 with mean -0.3203732549662849 and std 1.3916335599260157\n",
      "Standardizing g-187 with mean 0.0401891151813377 and std 1.0784883538644792\n",
      "Standardizing g-188 with mean 0.15317509568070045 and std 1.0816065249452669\n",
      "Standardizing g-189 with mean -0.013597580645161278 and std 1.7018509312198071\n",
      "Standardizing g-190 with mean 0.09764329323856341 and std 1.1927468683370968\n",
      "Standardizing g-191 with mean 0.27201880353562746 and std 1.4312551191352698\n",
      "Standardizing g-192 with mean 0.13507813012575168 and std 0.9742151400368306\n",
      "Standardizing g-193 with mean -0.016314989976307693 and std 0.8391724768365547\n",
      "Standardizing g-194 with mean -0.2463262347366505 and std 1.1858069980503751\n",
      "Standardizing g-195 with mean -0.41013190267905847 and std 1.7873249481257791\n",
      "Standardizing g-196 with mean -0.29075481592855956 and std 1.215734504882804\n",
      "Standardizing g-197 with mean 0.21963639967195264 and std 1.279577358653301\n",
      "Standardizing g-198 with mean 0.19735266539092317 and std 1.195579895027356\n",
      "Standardizing g-199 with mean -0.1302083697831241 and std 1.026539867682369\n",
      "Standardizing g-200 with mean 0.10507835338071728 and std 1.026604605414598\n",
      "Standardizing g-201 with mean 0.40428281848004494 and std 1.7309921894346716\n",
      "Standardizing g-202 with mean -0.23993793967559604 and std 1.7360075569782747\n",
      "Standardizing g-203 with mean -0.026963572990705356 and std 1.2723684634811485\n",
      "Standardizing g-204 with mean -0.1913745170402772 and std 1.2618505402483584\n",
      "Standardizing g-205 with mean 0.12601557317295464 and std 0.9594796472072161\n",
      "Standardizing g-206 with mean -0.13212323218516422 and std 1.4306462509114237\n",
      "Standardizing g-207 with mean 0.05455759522507767 and std 1.1188762179044234\n",
      "Standardizing g-208 with mean 0.46888483688718463 and std 1.8224326390341805\n",
      "Standardizing g-209 with mean 0.13836631128121069 and std 1.0444324336569262\n",
      "Standardizing g-210 with mean 0.09374312921450681 and std 1.172324718891713\n",
      "Standardizing g-211 with mean -0.09153552032075779 and std 1.0264831063644155\n",
      "Standardizing g-212 with mean -0.01335703025332597 and std 0.9144467385489151\n",
      "Standardizing g-213 with mean 0.19335684344815002 and std 1.0777075680197998\n",
      "Standardizing g-214 with mean -0.12158947512301856 and std 1.0919166575939847\n",
      "Standardizing g-215 with mean 0.31631825678877246 and std 1.645236531314306\n",
      "Standardizing g-216 with mean 0.0750461272097679 and std 0.7740621889550146\n",
      "Standardizing g-217 with mean -0.01130531711317655 and std 0.9688199410805244\n",
      "Standardizing g-218 with mean -0.0612487789320217 and std 1.3351609754541847\n",
      "Standardizing g-219 with mean 0.03980395935848341 and std 0.575919339791175\n",
      "Standardizing g-220 with mean 0.272702843083652 and std 1.2328349369329399\n",
      "Standardizing g-221 with mean 0.033536012392928916 and std 1.0643323295861329\n",
      "Standardizing g-222 with mean 0.010332868598505447 and std 1.0773339873693835\n",
      "Standardizing g-223 with mean -0.20700485237834926 and std 1.0121299935787955\n",
      "Standardizing g-224 with mean -0.007037853107344606 and std 1.2119846443667077\n",
      "Standardizing g-225 with mean 0.040588049024967605 and std 1.0062935397887096\n",
      "Standardizing g-226 with mean 0.2736031802442133 and std 1.5213017750530415\n",
      "Standardizing g-227 with mean -0.08422684071441541 and std 0.9646209608814623\n",
      "Standardizing g-228 with mean -0.5067676006925455 and std 2.2379828169753284\n",
      "Standardizing g-229 with mean 0.20588242664479572 and std 1.3744718548648327\n",
      "Standardizing g-230 with mean -0.00455239657371977 and std 1.0728065756078429\n",
      "Standardizing g-231 with mean -0.045948450883907276 and std 1.74057169411534\n",
      "Standardizing g-232 with mean 0.17364564425004542 and std 1.1929987275972078\n",
      "Standardizing g-233 with mean 0.02596813377073085 and std 0.8889184529159156\n",
      "Standardizing g-234 with mean -0.2523933479132481 and std 1.2988243193276054\n",
      "Standardizing g-235 with mean 0.26051987880444794 and std 1.4073891139954104\n",
      "Standardizing g-236 with mean 0.08175486149079625 and std 0.9368300108124913\n",
      "Standardizing g-237 with mean -0.043451535447421016 and std 0.913004040825022\n",
      "Standardizing g-238 with mean -0.28310696190996987 and std 1.1329071104203574\n",
      "Standardizing g-239 with mean -0.26562415254237165 and std 1.207526813998395\n",
      "Standardizing g-240 with mean 0.04321133132859495 and std 0.9642412532414416\n",
      "Standardizing g-241 with mean -0.17128624931656594 and std 1.327648600867881\n",
      "Standardizing g-242 with mean 0.13746971478039036 and std 1.1048818546213044\n",
      "Standardizing g-243 with mean 0.21070495717149632 and std 1.5395371622503944\n",
      "Standardizing g-244 with mean 0.2459283579369432 and std 1.1252198289010797\n",
      "Standardizing g-245 with mean 0.19597480863860056 and std 1.3220920627362833\n",
      "Standardizing g-246 with mean -0.034352464917076705 and std 1.001340647104685\n",
      "Standardizing g-247 with mean -0.036566388737014725 and std 1.1098428265117666\n",
      "Standardizing g-248 with mean 0.3842338436303982 and std 1.8736385897677281\n",
      "Standardizing g-249 with mean 0.17781714507016566 and std 1.173635053897705\n",
      "Standardizing g-250 with mean -0.4316072307271737 and std 1.7956602029481354\n",
      "Standardizing g-251 with mean 0.2500167258975767 and std 1.4224540765490752\n",
      "Standardizing g-252 with mean 0.05774540732640775 and std 1.243269509748429\n",
      "Standardizing g-253 with mean -0.0003621058866411408 and std 1.0302977868244698\n",
      "Standardizing g-254 with mean 0.08572323674138888 and std 1.343445716695687\n",
      "Standardizing g-255 with mean 0.1701832695462016 and std 1.2253201349720533\n",
      "Standardizing g-256 with mean -0.04070848368871862 and std 0.9785534652660622\n",
      "Standardizing g-257 with mean -0.5204251640240576 and std 1.916900148614223\n",
      "Standardizing g-258 with mean -0.043040664297430115 and std 1.1095209398093349\n",
      "Standardizing g-259 with mean 0.2675098870056473 and std 1.3897017532916103\n",
      "Standardizing g-260 with mean 0.02845307545106622 and std 0.9720060487859619\n",
      "Standardizing g-261 with mean 0.34301184618188335 and std 1.68488976635123\n",
      "Standardizing g-262 with mean -0.04715929925277968 and std 0.8228807778182442\n",
      "Standardizing g-263 with mean 0.07313073628576582 and std 0.9618621890411078\n",
      "Standardizing g-264 with mean 0.16682781119008652 and std 1.1782097153410775\n",
      "Standardizing g-265 with mean -0.014622480408237623 and std 1.0098839634516263\n",
      "Standardizing g-266 with mean 0.3155159240021889 and std 1.3929143785014493\n",
      "Standardizing g-267 with mean -0.2754585110260613 and std 0.8248902918763997\n",
      "Standardizing g-268 with mean -0.05505879351193735 and std 0.8480034059437117\n",
      "Standardizing g-269 with mean -0.04068564333880091 and std 1.0970768836379923\n",
      "Standardizing g-270 with mean 0.34945431474394 and std 1.6935667819626967\n",
      "Standardizing g-271 with mean -0.27369466921815266 and std 1.5468156274609106\n",
      "Standardizing g-272 with mean -0.14912327319117816 and std 1.3576855449238439\n",
      "Standardizing g-273 with mean -0.13402951066156327 and std 0.9852435120751221\n",
      "Standardizing g-274 with mean 0.027507139602697288 and std 0.8470482402367406\n",
      "Standardizing g-275 with mean -0.09479822762894093 and std 1.0976212844231914\n",
      "Standardizing g-276 with mean -0.39498177510479604 and std 1.3764658378191925\n",
      "Standardizing g-277 with mean -0.12089004009476934 and std 0.9945515938887594\n",
      "Standardizing g-278 with mean 0.11628615819209025 and std 0.9405649453591522\n",
      "Standardizing g-279 with mean 0.010768261344997244 and std 0.8383606266096189\n",
      "Standardizing g-280 with mean -0.008948692363768978 and std 1.0565387865303593\n",
      "Standardizing g-281 with mean -0.04268675961363208 and std 1.2745734855841435\n",
      "Standardizing g-282 with mean -0.12180170858392544 and std 1.1303458528722852\n",
      "Standardizing g-283 with mean -0.08694518862766545 and std 0.9564621464246539\n",
      "Standardizing g-284 with mean -0.09219147530526775 and std 1.0660703073861855\n",
      "Standardizing g-285 with mean -0.21284182613449915 and std 1.0973778859450138\n",
      "Standardizing g-286 with mean 0.19769898396209096 and std 1.0164952806874625\n",
      "Standardizing g-287 with mean -0.075470657918717 and std 1.1355469723325882\n",
      "Standardizing g-288 with mean -0.013086094404957227 and std 1.0205755695161367\n",
      "Standardizing g-289 with mean 0.2150239065062885 and std 1.2187350636148857\n",
      "Standardizing g-290 with mean 0.1370876161837065 and std 1.2530162774064395\n",
      "Standardizing g-291 with mean -0.23351940495717002 and std 1.5751492828030638\n",
      "Standardizing g-292 with mean -0.0017350920357207915 and std 0.8291026111119659\n",
      "Standardizing g-293 with mean -0.1345024922544196 and std 1.0944953605044005\n",
      "Standardizing g-294 with mean -0.21722249863313337 and std 1.3722998598944645\n",
      "Standardizing g-295 with mean 0.20833466830690583 and std 1.1627844453784781\n",
      "Standardizing g-296 with mean 0.05844065518498284 and std 1.0539594839765027\n",
      "Standardizing g-297 with mean -0.09743838618552957 and std 1.1945048202770001\n",
      "Standardizing g-298 with mean -0.46489950792783274 and std 1.7001655860907559\n",
      "Standardizing g-299 with mean -0.19502989338436227 and std 1.3094196159398825\n",
      "Standardizing g-300 with mean -0.13719054127938857 and std 1.985409248364649\n",
      "Standardizing g-301 with mean -0.13791844815017373 and std 1.0194739304980598\n",
      "Standardizing g-302 with mean 0.25540310734463245 and std 1.0900168832766057\n",
      "Standardizing g-303 with mean -0.04536047020229636 and std 0.7880167856388741\n",
      "Standardizing g-304 with mean -0.2716861399671966 and std 1.3234659983727404\n",
      "Standardizing g-305 with mean -0.04516184162566042 and std 0.9671080826958506\n",
      "Standardizing g-306 with mean -0.18988973482777463 and std 1.2599146891296644\n",
      "Standardizing g-307 with mean -0.1396447102241664 and std 0.6132509986883324\n",
      "Standardizing g-308 with mean 0.2373856433388015 and std 1.2537329914070576\n",
      "Standardizing g-309 with mean -0.07983102332786574 and std 1.1056178806560757\n",
      "Standardizing g-310 with mean 0.38515723072717245 and std 1.4320555445634222\n",
      "Standardizing g-311 with mean 0.016027956989247267 and std 1.1198969536676093\n",
      "Standardizing g-312 with mean -0.10410879351193683 and std 0.889091333200206\n",
      "Standardizing g-313 with mean 0.2699387461272085 and std 1.1462366100079378\n",
      "Standardizing g-314 with mean -0.20552007927829521 and std 1.3043432234402934\n",
      "Standardizing g-315 with mean -0.1517998952068509 and std 1.080453958906909\n",
      "Standardizing g-316 with mean -0.1595033624931661 and std 1.257205125746043\n",
      "Standardizing g-317 with mean 0.26174899763076237 and std 1.2885986034612913\n",
      "Standardizing g-318 with mean 0.014063431747767377 and std 0.8738882021458191\n",
      "Standardizing g-319 with mean -0.014063837251685743 and std 1.038333131763489\n",
      "Standardizing g-320 with mean 0.18454830508474582 and std 1.3233578527179124\n",
      "Standardizing g-321 with mean -0.1551626617459442 and std 1.1259915458891891\n",
      "Standardizing g-322 with mean -0.09543623109167135 and std 1.1617467615668524\n",
      "Standardizing g-323 with mean -0.053967263531984486 and std 1.0991253177837532\n",
      "Standardizing g-324 with mean -0.0407172088572991 and std 0.8734707922496349\n",
      "Standardizing g-325 with mean -0.14907782941498135 and std 1.071050913063375\n",
      "Standardizing g-326 with mean 0.2912379305631489 and std 1.1914321640926593\n",
      "Standardizing g-327 with mean -0.2497756788773469 and std 1.3518456030240702\n",
      "Standardizing g-328 with mean 0.4515779934390383 and std 1.9462208134497476\n",
      "Standardizing g-329 with mean -0.0909719837798431 and std 1.1873424208395384\n",
      "Standardizing g-330 with mean 0.15140770913067172 and std 1.1172842692143001\n",
      "Standardizing g-331 with mean 0.07269382176052473 and std 0.6375832127781299\n",
      "Standardizing g-332 with mean -0.47179530253326213 and std 1.9265886188768013\n",
      "Standardizing g-333 with mean 0.12802034353927524 and std 0.9737637492658427\n",
      "Standardizing g-334 with mean 0.32682458993985614 and std 1.4853553615974817\n",
      "Standardizing g-335 with mean 0.21401199653727 and std 1.2269645749428644\n",
      "Standardizing g-336 with mean 0.10387684527063992 and std 1.1128282857052756\n",
      "Standardizing g-337 with mean 0.20087489976307626 and std 1.1718000569900444\n",
      "Standardizing g-338 with mean -0.059238545653362666 and std 1.4371204230626153\n",
      "Standardizing g-339 with mean -0.1261985101148162 and std 1.0497653361410317\n",
      "Standardizing g-340 with mean 0.03185892108620383 and std 0.7778584568909228\n",
      "Standardizing g-341 with mean -0.06504278749772212 and std 1.0869757761405088\n",
      "Standardizing g-342 with mean -0.0755978767997086 and std 1.042394936305393\n",
      "Standardizing g-343 with mean 0.10522815290687029 and std 0.9508160354155643\n",
      "Standardizing g-344 with mean 0.35349194459631944 and std 1.436472986507823\n",
      "Standardizing g-345 with mean 0.07346885821031535 and std 0.850572108619696\n",
      "Standardizing g-346 with mean 0.08561414707490411 and std 0.9409969029893865\n",
      "Standardizing g-347 with mean -0.06662078093675958 and std 1.0207909998748126\n",
      "Standardizing g-348 with mean 0.1020388235830145 and std 0.9477392511060962\n",
      "Standardizing g-349 with mean 0.4158030800072865 and std 1.8225277736744003\n",
      "Standardizing g-350 with mean 0.10498831328594893 and std 1.0988196421439207\n",
      "Standardizing g-351 with mean -0.10532543739748479 and std 1.1390263179659277\n",
      "Standardizing g-352 with mean 0.09609116548204823 and std 0.9214060311836461\n",
      "Standardizing g-353 with mean -0.27705875250592255 and std 1.6073410266650834\n",
      "Standardizing g-354 with mean 0.19711365500273414 and std 1.099982707494395\n",
      "Standardizing g-355 with mean 0.10604748952068523 and std 0.9964867796477044\n",
      "Standardizing g-356 with mean 0.021314292874065974 and std 1.030445028748652\n",
      "Standardizing g-357 with mean -0.14580126207399385 and std 1.2411545764678784\n",
      "Standardizing g-358 with mean 0.16611133588481722 and std 1.1557789768257594\n",
      "Standardizing g-359 with mean 0.20353409877893214 and std 1.3438696551565572\n",
      "Standardizing g-360 with mean -0.30398140605066654 and std 1.3621109348484206\n",
      "Standardizing g-361 with mean 0.0896275059230913 and std 1.046423154344356\n",
      "Standardizing g-362 with mean 0.17597947876799752 and std 1.062927904810597\n",
      "Standardizing g-363 with mean -0.03986303991252011 and std 0.891377181180681\n",
      "Standardizing g-364 with mean -0.3202421496263903 and std 1.4131745442997234\n",
      "Standardizing g-365 with mean 0.2586457399307461 and std 1.270910277260007\n",
      "Standardizing g-366 with mean 0.12239116092582385 and std 1.0527156946019807\n",
      "Standardizing g-367 with mean 0.20924046837980695 and std 1.3137782893474308\n",
      "Standardizing g-368 with mean 0.34784375797339095 and std 1.5978543902960218\n",
      "Standardizing g-369 with mean -0.41708858665937504 and std 1.7799010986461914\n",
      "Standardizing g-370 with mean -0.6609225578640459 and std 1.5871475155800956\n",
      "Standardizing g-371 with mean -0.10517623929287409 and std 1.0842522982307046\n",
      "Standardizing g-372 with mean 0.05845203207581551 and std 1.1587738878158091\n",
      "Standardizing g-373 with mean -0.07484476489885168 and std 1.0348897233962753\n",
      "Standardizing g-374 with mean 0.3200691725897562 and std 1.6169434094307666\n",
      "Standardizing g-375 with mean -0.464569213595769 and std 1.6001874028115006\n",
      "Standardizing g-376 with mean 0.06983562055768143 and std 1.3124965905136277\n",
      "Standardizing g-377 with mean 0.23658471842536963 and std 1.2644846518504371\n",
      "Standardizing g-378 with mean -0.056120434663750475 and std 1.0884377629806516\n",
      "Standardizing g-379 with mean -0.23432489520685248 and std 1.5092579147768261\n",
      "Standardizing g-380 with mean 0.23606078913796255 and std 1.1100257741170798\n",
      "Standardizing g-381 with mean 0.10001814288317856 and std 1.05633144827516\n",
      "Standardizing g-382 with mean -0.04121897211591048 and std 0.8157678419242829\n",
      "Standardizing g-383 with mean -0.06666211499908933 and std 0.9023988355727203\n",
      "Standardizing g-384 with mean -0.07549221341352302 and std 0.9935263592579027\n",
      "Standardizing g-385 with mean -0.222026052487698 and std 1.887805514663023\n",
      "Standardizing g-386 with mean 0.301647343721522 and std 1.7105178472750862\n",
      "Standardizing g-387 with mean 0.04724669673774385 and std 1.008901474068847\n",
      "Standardizing g-388 with mean -0.11815844723892781 and std 1.0208311295111365\n",
      "Standardizing g-389 with mean 0.09244786313103757 and std 1.0971837785044316\n",
      "Standardizing g-390 with mean -0.05489504738472713 and std 1.2235373711511768\n",
      "Standardizing g-391 with mean 0.28187670402770176 and std 1.0851530164938736\n",
      "Standardizing g-392 with mean 0.5767032485875646 and std 2.049622392673648\n",
      "Standardizing g-393 with mean 0.23501025150355523 and std 1.1821061112935478\n",
      "Standardizing g-394 with mean -0.035439106068889885 and std 1.2661377691996811\n",
      "Standardizing g-395 with mean 0.006254510661563645 and std 1.250051986314849\n",
      "Standardizing g-396 with mean -0.14252556497175148 and std 0.8673121690190471\n",
      "Standardizing g-397 with mean 0.03384423637689071 and std 1.0028440563706558\n",
      "Standardizing g-398 with mean 0.004411736832513254 and std 1.1157971667396624\n",
      "Standardizing g-399 with mean -0.21539277838527454 and std 1.2182699579634981\n",
      "Standardizing g-400 with mean -0.17886781027884016 and std 1.051682735380229\n",
      "Standardizing g-401 with mean -0.21559998633132985 and std 1.1439565021001958\n",
      "Standardizing g-402 with mean 0.222753704209952 and std 1.3806750710308466\n",
      "Standardizing g-403 with mean 0.16051197375615078 and std 1.0117617469056788\n",
      "Standardizing g-404 with mean -0.024488964825952395 and std 0.8342501327080646\n",
      "Standardizing g-405 with mean -0.10159617732823127 and std 1.1713730612631852\n",
      "Standardizing g-406 with mean -0.45914904774922477 and std 1.9423103826904131\n",
      "Standardizing g-407 with mean -0.2134812329141603 and std 1.2441916271841482\n",
      "Standardizing g-408 with mean 0.06961343174776757 and std 0.9484466263071942\n",
      "Standardizing g-409 with mean 0.23780915800984018 and std 1.2407556471166226\n",
      "Standardizing g-410 with mean -0.2912378941133594 and std 1.367433017501528\n",
      "Standardizing g-411 with mean -0.4301669992710009 and std 1.7812089919297767\n",
      "Standardizing g-412 with mean -0.1481863131036997 and std 0.9923155393945053\n",
      "Standardizing g-413 with mean 0.37490640605066294 and std 1.1206394168069536\n",
      "Standardizing g-414 with mean -0.20043546108984883 and std 1.3158590821943328\n",
      "Standardizing g-415 with mean -0.0033875113905595285 and std 0.9312810065746387\n",
      "Standardizing g-416 with mean 0.13825268817204298 and std 1.0022457779348035\n",
      "Standardizing g-417 with mean 0.49322582012028326 and std 2.001760613114058\n",
      "Standardizing g-418 with mean 0.2853901221067985 and std 1.2849633677387151\n",
      "Standardizing g-419 with mean 0.019127947876799712 and std 1.1029214715934186\n",
      "Standardizing g-420 with mean -0.03826215144887914 and std 0.8221470927722038\n",
      "Standardizing g-421 with mean -0.3766798478221262 and std 1.2698978846057407\n",
      "Standardizing g-422 with mean 0.1490061964643695 and std 1.2781747688310698\n",
      "Standardizing g-423 with mean -0.21672052123200472 and std 1.515288528498194\n",
      "Standardizing g-424 with mean 0.2782116047020234 and std 1.4093335949960644\n",
      "Standardizing g-425 with mean 0.3088766447967923 and std 1.1552942292109516\n",
      "Standardizing g-426 with mean 0.2511978631310367 and std 1.2159851201584628\n",
      "Standardizing g-427 with mean 0.23838167942409366 and std 1.4265672570092285\n",
      "Standardizing g-428 with mean -0.17035226444322962 and std 1.2071418705673063\n",
      "Standardizing g-429 with mean -0.21744202660834658 and std 1.226211996744549\n",
      "Standardizing g-430 with mean 0.2902955485693446 and std 0.9114766467183218\n",
      "Standardizing g-431 with mean 0.0360734235465647 and std 1.1152942066014713\n",
      "Standardizing g-432 with mean -0.13237810734463218 and std 1.0019176500740874\n",
      "Standardizing g-433 with mean -0.30622732367413846 and std 1.4196938709862712\n",
      "Standardizing g-434 with mean -0.20773329688354383 and std 1.4205497760880332\n",
      "Standardizing g-435 with mean 0.06411164115181327 and std 0.6609833680673785\n",
      "Standardizing g-436 with mean 0.17970816930927744 and std 1.1756127917186645\n",
      "Standardizing g-437 with mean 0.24685759978130212 and std 1.1775114661957167\n",
      "Standardizing g-438 with mean -0.33229862402041077 and std 1.3794266922516794\n",
      "Standardizing g-439 with mean -0.45207936030617685 and std 1.563745153171263\n",
      "Standardizing g-440 with mean -0.21662864953526478 and std 1.0999053647239367\n",
      "Standardizing g-441 with mean 0.1944635866593764 and std 1.1877428430473145\n",
      "Standardizing g-442 with mean 0.07477988882813907 and std 1.0547634253895852\n",
      "Standardizing g-443 with mean 0.31707390195006524 and std 1.547174501491618\n",
      "Standardizing g-444 with mean -0.07042203845452881 and std 1.0057613565948742\n",
      "Standardizing g-445 with mean -0.04208285037361013 and std 0.9833650982750183\n",
      "Standardizing g-446 with mean -0.07089542099507991 and std 0.9598524437385393\n",
      "Standardizing g-447 with mean 0.1084504738472757 and std 1.0290182739532923\n",
      "Standardizing g-448 with mean 0.012586586477127685 and std 0.9687540045576424\n",
      "Standardizing g-449 with mean -0.12371661654820487 and std 1.4024753596119217\n",
      "Standardizing g-450 with mean -0.004946282121377823 and std 1.0728739774879887\n",
      "Standardizing g-451 with mean 0.11426707217058522 and std 1.1546773894674403\n",
      "Standardizing g-452 with mean 0.2713537042099504 and std 1.19057490064394\n",
      "Standardizing g-453 with mean -0.03691746856205581 and std 0.9900686982345688\n",
      "Standardizing g-454 with mean 0.058025255148533336 and std 0.8424398387089935\n",
      "Standardizing g-455 with mean 0.08883707399307424 and std 1.1043382324137558\n",
      "Standardizing g-456 with mean -0.016837397484964375 and std 1.230334298697113\n",
      "Standardizing g-457 with mean 0.09071099416803383 and std 1.1372425294426383\n",
      "Standardizing g-458 with mean 0.08568788955713537 and std 1.1508448761266488\n",
      "Standardizing g-459 with mean -0.06586899034080582 and std 1.113963353099547\n",
      "Standardizing g-460 with mean 0.43782185620557706 and std 1.853189186845751\n",
      "Standardizing g-461 with mean 0.1394147758337879 and std 1.0468851441687617\n",
      "Standardizing g-462 with mean 0.14916571441589316 and std 1.105023602153943\n",
      "Standardizing g-463 with mean 0.03755343539274642 and std 0.9556994660425625\n",
      "Standardizing g-464 with mean -0.11149268270457419 and std 1.5720603581312964\n",
      "Standardizing g-465 with mean -0.027202478585748306 and std 1.2002862887088221\n",
      "Standardizing g-466 with mean 0.09239410880262405 and std 1.0164240344075142\n",
      "Standardizing g-467 with mean 0.15009294240933035 and std 1.5177988453209084\n",
      "Standardizing g-468 with mean 0.285886039730272 and std 1.4552063058106393\n",
      "Standardizing g-469 with mean 0.08256463914707533 and std 0.9935718574349548\n",
      "Standardizing g-470 with mean -0.26331470293420867 and std 1.342675135519676\n",
      "Standardizing g-471 with mean 0.020279451430654283 and std 0.8886186088430542\n",
      "Standardizing g-472 with mean 0.044363290504829546 and std 0.8590177907197305\n",
      "Standardizing g-473 with mean -0.12583509203572013 and std 0.91190454957122\n",
      "Standardizing g-474 with mean -0.1799031848004369 and std 1.2283221422419148\n",
      "Standardizing g-475 with mean -0.012256838891926393 and std 1.093933442473896\n",
      "Standardizing g-476 with mean -0.03413379806816123 and std 0.9563024519181919\n",
      "Standardizing g-477 with mean -0.5048409969017684 and std 1.7123841572997545\n",
      "Standardizing g-478 with mean 0.341470762711863 and std 1.6145308402555372\n",
      "Standardizing g-479 with mean -0.1361965873883721 and std 1.0290389015861179\n",
      "Standardizing g-480 with mean 0.10702252141425236 and std 1.1100550226346522\n",
      "Standardizing g-481 with mean 0.08193711955531262 and std 0.6546327303926347\n",
      "Standardizing g-482 with mean -0.08422587935119391 and std 0.8765293644590796\n",
      "Standardizing g-483 with mean -0.10432283123747021 and std 0.9779888007523\n",
      "Standardizing g-484 with mean 0.36346571897211544 and std 1.4489316882633576\n",
      "Standardizing g-485 with mean -0.09424430472024747 and std 0.8537409444158939\n",
      "Standardizing g-486 with mean -0.29771728631310523 and std 1.6240732670801177\n",
      "Standardizing g-487 with mean -0.04038870512119558 and std 1.439611312622517\n",
      "Standardizing g-488 with mean 0.13815569527975277 and std 1.0810907203530515\n",
      "Standardizing g-489 with mean -0.5437684390377243 and std 2.0236895590562782\n",
      "Standardizing g-490 with mean -0.1913503371605607 and std 0.9348343876889028\n",
      "Standardizing g-491 with mean 0.2938897257153264 and std 1.3142726523529582\n",
      "Standardizing g-492 with mean 0.05865863404410485 and std 1.1817377153599793\n",
      "Standardizing g-493 with mean 0.05373039001275769 and std 0.9960440373026368\n",
      "Standardizing g-494 with mean 0.19680495717149782 and std 1.1246320041732387\n",
      "Standardizing g-495 with mean -0.2137751959176224 and std 1.3600629156346928\n",
      "Standardizing g-496 with mean 0.19067404319300138 and std 1.025790531619501\n",
      "Standardizing g-497 with mean -0.10273539730271566 and std 1.380205575833844\n",
      "Standardizing g-498 with mean -0.16466958264989973 and std 1.164914541092258\n",
      "Standardizing g-499 with mean -0.021247781119008616 and std 1.1623254193548898\n",
      "Standardizing g-500 with mean 0.2788770138509228 and std 1.489724664771761\n",
      "Standardizing g-501 with mean -0.0024939037725532965 and std 0.9249580633360323\n",
      "Standardizing g-502 with mean 0.07454769910698016 and std 0.9997599653201187\n",
      "Standardizing g-503 with mean -0.32127815746309557 and std 1.7769612823473464\n",
      "Standardizing g-504 with mean 0.13990473391652983 and std 1.2453311913472844\n",
      "Standardizing g-505 with mean 0.16630047840349949 and std 1.058919826450176\n",
      "Standardizing g-506 with mean 0.15232823491889888 and std 1.5036676224962424\n",
      "Standardizing g-507 with mean -0.004017240750865699 and std 0.8283548279227929\n",
      "Standardizing g-508 with mean -0.6853778430836531 and std 1.9835158890357965\n",
      "Standardizing g-509 with mean -0.13274548933843686 and std 1.0973658005331148\n",
      "Standardizing g-510 with mean -0.09569323400765453 and std 0.9171383805220057\n",
      "Standardizing g-511 with mean -0.05291293511937276 and std 0.9765235835197067\n",
      "Standardizing g-512 with mean 0.3424944550756349 and std 1.7594384254451079\n",
      "Standardizing g-513 with mean -0.05814433205759051 and std 1.4364835384920775\n",
      "Standardizing g-514 with mean 0.3487866138144704 and std 1.115372592234644\n",
      "Standardizing g-515 with mean 0.029357973391653018 and std 0.9991543260641886\n",
      "Standardizing g-516 with mean -0.15623956169127162 and std 0.8959969209180103\n",
      "Standardizing g-517 with mean 0.0789471113541096 and std 0.9403322360740277\n",
      "Standardizing g-518 with mean -0.002963317842172427 and std 0.8877455233191003\n",
      "Standardizing g-519 with mean 0.27485198651357795 and std 1.195945143694452\n",
      "Standardizing g-520 with mean -0.1242828913796247 and std 1.0865134501939224\n",
      "Standardizing g-521 with mean -0.09197298614907909 and std 1.1043859855545226\n",
      "Standardizing g-522 with mean -0.12576303991252094 and std 1.5735529375241468\n",
      "Standardizing g-523 with mean -0.09218731091671212 and std 0.8832448440037473\n",
      "Standardizing g-524 with mean -0.00271891288500092 and std 0.9126311469629184\n",
      "Standardizing g-525 with mean 0.01471538181155463 and std 1.0239073142437258\n",
      "Standardizing g-526 with mean -0.1560575587752879 and std 1.0507509159212003\n",
      "Standardizing g-527 with mean 0.2385856023327872 and std 1.0015136823632198\n",
      "Standardizing g-528 with mean 0.07003080462912364 and std 0.9392885011487949\n",
      "Standardizing g-529 with mean 0.26957522781119 and std 1.4196406009541285\n",
      "Standardizing g-530 with mean -0.18519639147074876 and std 1.1800304597379776\n",
      "Standardizing g-531 with mean 0.3012974257335516 and std 1.2160444163845978\n",
      "Standardizing g-532 with mean 0.04300728995808281 and std 0.9774743648750884\n",
      "Standardizing g-533 with mean -0.03600068798979426 and std 1.3221779235037272\n",
      "Standardizing g-534 with mean -0.37864187625296236 and std 1.5073860335892286\n",
      "Standardizing g-535 with mean 0.11170231456169122 and std 1.104233783992262\n",
      "Standardizing g-536 with mean -0.08925694368507375 and std 0.6801989868052388\n",
      "Standardizing g-537 with mean -0.12582922361946353 and std 1.3795569121056088\n",
      "Standardizing g-538 with mean -0.12789333880080198 and std 0.9582581557192777\n",
      "Standardizing g-539 with mean 0.15203450883907388 and std 1.0779672191967924\n",
      "Standardizing g-540 with mean -0.15602490431930102 and std 1.254139100090239\n",
      "Standardizing g-541 with mean 0.2839781392381986 and std 1.4244786872080295\n",
      "Standardizing g-542 with mean -0.059561996537269464 and std 0.85328153059888\n",
      "Standardizing g-543 with mean -0.06798352469473291 and std 1.2769933755349612\n",
      "Standardizing g-544 with mean 0.18942169218152063 and std 1.2408881824662354\n",
      "Standardizing g-545 with mean -0.12491445689812337 and std 0.9732702718097118\n",
      "Standardizing g-546 with mean 0.2765407144158906 and std 1.5073865039106413\n",
      "Standardizing g-547 with mean 0.08934348459996372 and std 0.8895033228567674\n",
      "Standardizing g-548 with mean 0.11187397940586855 and std 1.2223459308038627\n",
      "Standardizing g-549 with mean 0.009949097867687294 and std 0.8827066688426066\n",
      "Standardizing g-550 with mean -0.036981510843812605 and std 0.62387304979301\n",
      "Standardizing g-551 with mean 0.1540423318753414 and std 1.1672464968520297\n",
      "Standardizing g-552 with mean -0.053551562784763966 and std 0.8290092679604117\n",
      "Standardizing g-553 with mean -0.18797703663203988 and std 1.2607809157794183\n",
      "Standardizing g-554 with mean -0.13893140605066487 and std 0.9929447077311905\n",
      "Standardizing g-555 with mean -0.33075636960087496 and std 1.169155447768622\n",
      "Standardizing g-556 with mean -0.159390668853654 and std 1.1265299142361367\n",
      "Standardizing g-557 with mean 0.08102147803900121 and std 0.9115540675669924\n",
      "Standardizing g-558 with mean -0.18792068525605934 and std 1.2689132246117907\n",
      "Standardizing g-559 with mean -0.14269821396026963 and std 1.1030278920951873\n",
      "Standardizing g-560 with mean -0.09079362584290142 and std 0.8066318696342735\n",
      "Standardizing g-561 with mean -0.2590123382540554 and std 1.436236754213295\n",
      "Standardizing g-562 with mean -0.09566428831784297 and std 1.0906618005959647\n",
      "Standardizing g-563 with mean -0.05043673227628941 and std 1.1360538996732825\n",
      "Standardizing g-564 with mean 0.021511108073628504 and std 1.2465879446643071\n",
      "Standardizing g-565 with mean -0.18617205667942383 and std 1.439689887311734\n",
      "Standardizing g-566 with mean 0.014724480590486578 and std 0.9572487322823492\n",
      "Standardizing g-567 with mean -0.21679420903954746 and std 0.9740386881328659\n",
      "Standardizing g-568 with mean -0.5139490568616722 and std 1.63570780825349\n",
      "Standardizing g-569 with mean -0.376788636777838 and std 1.6658053381537132\n",
      "Standardizing g-570 with mean 0.014924731182795758 and std 1.032056836804742\n",
      "Standardizing g-571 with mean -0.3459779114270102 and std 1.2973143209661147\n",
      "Standardizing g-572 with mean 0.23981389648259618 and std 1.1301592385532446\n",
      "Standardizing g-573 with mean 0.07168701020594084 and std 0.9585361220300309\n",
      "Standardizing g-574 with mean -0.2783389967195191 and std 1.2745473697122218\n",
      "Standardizing g-575 with mean -0.004966921815199569 and std 1.031312961153463\n",
      "Standardizing g-576 with mean 0.2951325132130498 and std 1.2336518213632943\n",
      "Standardizing g-577 with mean -0.03268392564242756 and std 1.1609950284793964\n",
      "Standardizing g-578 with mean 0.29450292965190666 and std 1.3691966016523986\n",
      "Standardizing g-579 with mean -0.12767542828503764 and std 1.257444502827713\n",
      "Standardizing g-580 with mean 0.1306696282121381 and std 0.9286236216240072\n",
      "Standardizing g-581 with mean -0.08223739748496428 and std 0.8397260784464115\n",
      "Standardizing g-582 with mean 0.08858944322945156 and std 1.199616383652484\n",
      "Standardizing g-583 with mean 0.0036025651540003505 and std 0.8125068641133776\n",
      "Standardizing g-584 with mean 0.06495641971933615 and std 1.020179859264656\n",
      "Standardizing g-585 with mean -0.2918248496446148 and std 1.224749514052718\n",
      "Standardizing g-586 with mean -0.14236164570803672 and std 1.0470006365396547\n",
      "Standardizing g-587 with mean -0.04023838162930559 and std 0.9402715430023404\n",
      "Standardizing g-588 with mean -0.1996899626389645 and std 1.3173343271304776\n",
      "Standardizing g-589 with mean 0.009765459267359203 and std 0.9964573242669672\n",
      "Standardizing g-590 with mean -0.1862613404410428 and std 1.1227052367669506\n",
      "Standardizing g-591 with mean -0.04906537725533062 and std 1.1270016874943363\n",
      "Standardizing g-592 with mean 0.22863540641516353 and std 1.2177385640119314\n",
      "Standardizing g-593 with mean 0.08150486149079612 and std 0.9703449681249967\n",
      "Standardizing g-594 with mean 0.1648271186440679 and std 1.0881543578309263\n",
      "Standardizing g-595 with mean -0.2900674867869502 and std 1.3282530783484368\n",
      "Standardizing g-596 with mean 0.2956185529433202 and std 1.3613819015324329\n",
      "Standardizing g-597 with mean -0.24603641334062512 and std 1.330249728029924\n",
      "Standardizing g-598 with mean -0.1593256287588854 and std 1.0187940024317832\n",
      "Standardizing g-599 with mean 0.2712964096956439 and std 1.29525552049737\n",
      "Standardizing g-600 with mean 0.20783119190814686 and std 1.2921789961982726\n",
      "Standardizing g-601 with mean -0.10303867322762933 and std 0.9312159899989915\n",
      "Standardizing g-602 with mean 0.21848721523601283 and std 1.1994508373973982\n",
      "Standardizing g-603 with mean 0.1734546017860403 and std 1.2396919114194327\n",
      "Standardizing g-604 with mean -0.033741329506105464 and std 1.178880525567654\n",
      "Standardizing g-605 with mean -0.05467244395844711 and std 1.023933199711246\n",
      "Standardizing g-606 with mean 0.047526590122106596 and std 0.9199136264208811\n",
      "Standardizing g-607 with mean 0.24519864680153072 and std 1.1919022484344963\n",
      "Standardizing g-608 with mean 0.3261473938399836 and std 1.305154002114664\n",
      "Standardizing g-609 with mean 0.12510765445598718 and std 1.0764604619162275\n",
      "Standardizing g-610 with mean -0.18578896026972846 and std 1.041138588257476\n",
      "Standardizing g-611 with mean 0.06720693457262589 and std 0.6986830033042425\n",
      "Standardizing g-612 with mean -0.1418761117186072 and std 1.1074256570866199\n",
      "Standardizing g-613 with mean 0.04409358483688743 and std 1.1802284268879595\n",
      "Standardizing g-614 with mean -0.07384972207034798 and std 1.0838523047072843\n",
      "Standardizing g-615 with mean -0.12790987789320157 and std 1.1957412754785268\n",
      "Standardizing g-616 with mean -0.11368412156005077 and std 1.0430969192717972\n",
      "Standardizing g-617 with mean -0.038468603061782285 and std 0.9978487278953941\n",
      "Standardizing g-618 with mean -0.2931369281939151 and std 1.1060585755190144\n",
      "Standardizing g-619 with mean 0.1499092126845273 and std 1.121743548646287\n",
      "Standardizing g-620 with mean 0.2259583606706765 and std 1.3232207424093567\n",
      "Standardizing g-621 with mean -0.12936178239475066 and std 1.1043729938771056\n",
      "Standardizing g-622 with mean 0.02800180426462562 and std 0.9084265660164647\n",
      "Standardizing g-623 with mean 0.07024592217969745 and std 1.0153851599634505\n",
      "Standardizing g-624 with mean 0.1679036495352657 and std 1.3526994191285948\n",
      "Standardizing g-625 with mean 0.2057780390012762 and std 1.3865012287545584\n",
      "Standardizing g-626 with mean -0.07515364953526517 and std 0.9877995953769433\n",
      "Standardizing g-627 with mean -0.003342855841078917 and std 0.9539987013652903\n",
      "Standardizing g-628 with mean 0.22088594860579575 and std 1.2023022668408028\n",
      "Standardizing g-629 with mean 0.2548555358119194 and std 1.652933595594982\n",
      "Standardizing g-630 with mean -0.11454756242026544 and std 1.104173555353377\n",
      "Standardizing g-631 with mean 0.06299597229815891 and std 1.1101391158458076\n",
      "Standardizing g-632 with mean -0.3314966329506084 and std 1.5535573680415877\n",
      "Standardizing g-633 with mean 0.0017151403316930738 and std 0.8585633072964659\n",
      "Standardizing g-634 with mean 0.09447232094040431 and std 0.985440718979402\n",
      "Standardizing g-635 with mean 0.2519712274466937 and std 1.4636329181260532\n",
      "Standardizing g-636 with mean 0.11934184891561896 and std 1.2250633222100118\n",
      "Standardizing g-637 with mean -0.1430633223983961 and std 1.0634186990781793\n",
      "Standardizing g-638 with mean -0.18922618006196473 and std 1.1682561790707493\n",
      "Standardizing g-639 with mean -0.1615101603790777 and std 1.2358723203813546\n",
      "Standardizing g-640 with mean 0.03241509021323115 and std 1.0851900848316782\n",
      "Standardizing g-641 with mean -0.15389791324949997 and std 1.0218329789661011\n",
      "Standardizing g-642 with mean 0.0640191817022053 and std 0.98633289071424\n",
      "Standardizing g-643 with mean -0.06833656825223282 and std 1.4178208005270516\n",
      "Standardizing g-644 with mean -0.47240319846910944 and std 1.7318751439869589\n",
      "Standardizing g-645 with mean 0.2385243894660121 and std 1.1758562053209773\n",
      "Standardizing g-646 with mean 0.2382697648988519 and std 1.3212243173005223\n",
      "Standardizing g-647 with mean 0.19665535811919208 and std 1.2584084970768077\n",
      "Standardizing g-648 with mean 0.18088428102788334 and std 1.1975341058193263\n",
      "Standardizing g-649 with mean -0.003928075451066161 and std 0.8920739497134834\n",
      "Standardizing g-650 with mean 0.2261193867322747 and std 1.2417733179485855\n",
      "Standardizing g-651 with mean -0.07379284217240781 and std 0.9342354190354867\n",
      "Standardizing g-652 with mean -0.13643790322580635 and std 1.0535759854524367\n",
      "Standardizing g-653 with mean -0.27937891835246925 and std 1.3256698523600807\n",
      "Standardizing g-654 with mean 0.24549070074722018 and std 1.233503099762838\n",
      "Standardizing g-655 with mean 0.34597168762529396 and std 1.0734335947202114\n",
      "Standardizing g-656 with mean -0.0347479269181705 and std 1.0831837783108793\n",
      "Standardizing g-657 with mean -0.07685696190996892 and std 0.9304888701364304\n",
      "Standardizing g-658 with mean 0.09376622926918177 and std 1.0798010332091326\n",
      "Standardizing g-659 with mean -0.11027587479496971 and std 0.9779565380457632\n",
      "Standardizing g-660 with mean -0.16085851558228587 and std 1.1242064058946473\n",
      "Standardizing g-661 with mean -0.1599163841807902 and std 1.1644439884317108\n",
      "Standardizing g-662 with mean 0.023177751959176325 and std 1.0649455427225447\n",
      "Standardizing g-663 with mean 0.29929187169673593 and std 1.3200644791944345\n",
      "Standardizing g-664 with mean -0.30514255513030825 and std 1.4148653801617292\n",
      "Standardizing g-665 with mean -0.23454502460360924 and std 1.3598688903843805\n",
      "Standardizing g-666 with mean 0.3006850692546021 and std 1.1426872190999062\n",
      "Standardizing g-667 with mean -0.07900695735374517 and std 0.90331392025065\n",
      "Standardizing g-668 with mean -0.15250261982868563 and std 1.0026605513792672\n",
      "Standardizing g-669 with mean -0.2864347503189351 and std 1.5008645499114062\n",
      "Standardizing g-670 with mean -0.1278105203207583 and std 1.1424086002490645\n",
      "Standardizing g-671 with mean 0.08356119919810454 and std 1.339457912501508\n",
      "Standardizing g-672 with mean -0.5689915937670899 and std 2.0264360447070247\n",
      "Standardizing g-673 with mean -0.08452737834882419 and std 1.3990568129397296\n",
      "Standardizing g-674 with mean -0.31972817568798917 and std 1.5965912431506089\n",
      "Standardizing g-675 with mean -0.02118972571532716 and std 0.9896542849691662\n",
      "Standardizing g-676 with mean 0.10185028248587562 and std 0.9330327783255095\n",
      "Standardizing g-677 with mean -0.1829418853654082 and std 1.2018333642682695\n",
      "Standardizing g-678 with mean -0.2136725578640427 and std 1.3070555780723765\n",
      "Standardizing g-679 with mean 0.09955859759431326 and std 0.9655049922327283\n",
      "Standardizing g-680 with mean -0.2107963003462733 and std 1.0705432050764545\n",
      "Standardizing g-681 with mean 0.023088363404410547 and std 1.0975603037038335\n",
      "Standardizing g-682 with mean 0.14392940586841652 and std 0.9989620510348366\n",
      "Standardizing g-683 with mean 0.179433246765082 and std 1.2046271389539545\n",
      "Standardizing g-684 with mean -0.14650963641334003 and std 0.9733297633608193\n",
      "Standardizing g-685 with mean -0.09992838071806093 and std 1.190074567785698\n",
      "Standardizing g-686 with mean -0.06623615363586724 and std 1.2604357824985088\n",
      "Standardizing g-687 with mean 0.000780207763805333 and std 0.7676195843620575\n",
      "Standardizing g-688 with mean 0.0969021550938583 and std 0.9130695365681859\n",
      "Standardizing g-689 with mean 0.3179143429925278 and std 1.543772001646638\n",
      "Standardizing g-690 with mean 0.08818707854929873 and std 0.934695166021931\n",
      "Standardizing g-691 with mean -0.3018716420630599 and std 1.60576535136255\n",
      "Standardizing g-692 with mean 0.1824567432112269 and std 1.0266302174229196\n",
      "Standardizing g-693 with mean 0.18375677054856968 and std 1.1766418902652545\n",
      "Standardizing g-694 with mean -0.06237858119190837 and std 1.0555366160941417\n",
      "Standardizing g-695 with mean 0.17514423182066652 and std 1.1932011896472894\n",
      "Standardizing g-696 with mean 0.13874936668489213 and std 1.0905698864717268\n",
      "Standardizing g-697 with mean 0.10299787679970843 and std 1.1852571042061268\n",
      "Standardizing g-698 with mean 0.013290655184982637 and std 1.0211584295316534\n",
      "Standardizing g-699 with mean 0.08831637051211921 and std 1.2084217180228245\n",
      "Standardizing g-700 with mean 0.06525953162019325 and std 1.1304822860061605\n",
      "Standardizing g-701 with mean -0.06821787862219753 and std 1.092674138579289\n",
      "Standardizing g-702 with mean -0.1402876799708397 and std 1.030941877473068\n",
      "Standardizing g-703 with mean -0.032506488062693524 and std 1.470809692165192\n",
      "Standardizing g-704 with mean -0.24155076088937372 and std 1.7549214420808714\n",
      "Standardizing g-705 with mean -0.40087962001093286 and std 1.7191203956828556\n",
      "Standardizing g-706 with mean -0.06192388372516816 and std 1.2385118777067412\n",
      "Standardizing g-707 with mean 0.744688336067067 and std 1.4576891030224322\n",
      "Standardizing g-708 with mean 0.20189241388736948 and std 1.4976946754807974\n",
      "Standardizing g-709 with mean -0.05265352651722253 and std 0.983633626989527\n",
      "Standardizing g-710 with mean 0.14222214780389966 and std 1.0102059791281532\n",
      "Standardizing g-711 with mean 0.09485380444687486 and std 1.50812377913738\n",
      "Standardizing g-712 with mean 0.3702065108438132 and std 1.8432902029618554\n",
      "Standardizing g-713 with mean 0.2022224302897759 and std 0.968394172274412\n",
      "Standardizing g-714 with mean 0.2013506105339901 and std 1.3267019360095633\n",
      "Standardizing g-715 with mean -0.15350211864406751 and std 1.188868991146075\n",
      "Standardizing g-716 with mean -0.046787247129578935 and std 0.8970343639535134\n",
      "Standardizing g-717 with mean -0.02991927738290516 and std 1.0448376607586765\n",
      "Standardizing g-718 with mean 0.06278057226171016 and std 0.7268719536227863\n",
      "Standardizing g-719 with mean -0.23701047931474525 and std 1.308427268136304\n",
      "Standardizing g-720 with mean 0.09244571714962577 and std 1.2594753723632028\n",
      "Standardizing g-721 with mean 0.344531825223256 and std 1.3350044075697816\n",
      "Standardizing g-722 with mean 0.03879148441771459 and std 0.9772160573053549\n",
      "Standardizing g-723 with mean 0.33603347002004624 and std 1.9574031850758022\n",
      "Standardizing g-724 with mean 0.2660179788591202 and std 1.4144464003350115\n",
      "Standardizing g-725 with mean 0.2067717878622193 and std 1.1435943291419173\n",
      "Standardizing g-726 with mean -0.2177715737197023 and std 1.2251425228921649\n",
      "Standardizing g-727 with mean -0.07305200018224886 and std 0.9017076004859585\n",
      "Standardizing g-728 with mean 0.1400803717878618 and std 1.2353943430842276\n",
      "Standardizing g-729 with mean 0.2964019363951142 and std 1.2817310578275032\n",
      "Standardizing g-730 with mean -0.047878353380718074 and std 0.935622974433001\n",
      "Standardizing g-731 with mean 0.5114407371970149 and std 1.9812135208545787\n",
      "Standardizing g-732 with mean 0.27408398487333685 and std 1.0909358308199502\n",
      "Standardizing g-733 with mean -0.26713794423182 and std 1.331377489365762\n",
      "Standardizing g-734 with mean 0.07994295152177858 and std 0.8752091747190751\n",
      "Standardizing g-735 with mean -0.04730311190085667 and std 0.9142930258268224\n",
      "Standardizing g-736 with mean -0.05694210862037533 and std 1.2066374885253532\n",
      "Standardizing g-737 with mean 0.20008823127391878 and std 1.2168927135179832\n",
      "Standardizing g-738 with mean -0.04877210224166199 and std 1.1803945117484038\n",
      "Standardizing g-739 with mean -0.21863997630763518 and std 1.1926603507478921\n",
      "Standardizing g-740 with mean 0.09337174685620521 and std 1.060591214690229\n",
      "Standardizing g-741 with mean 0.031127332786586574 and std 0.9996874895586663\n",
      "Standardizing g-742 with mean -0.2246912657189736 and std 1.0482620970134193\n",
      "Standardizing g-743 with mean -0.2898734098778945 and std 1.406802715622423\n",
      "Standardizing g-744 with mean 0.5891772781119021 and std 2.085718604526476\n",
      "Standardizing g-745 with mean 0.27816399671951864 and std 1.6780590900733117\n",
      "Standardizing g-746 with mean 0.10622171951886229 and std 1.243742534753886\n",
      "Standardizing g-747 with mean 0.06518547020229634 and std 0.9582697878851097\n",
      "Standardizing g-748 with mean 0.22024246856205518 and std 1.3070587984039943\n",
      "Standardizing g-749 with mean -0.05082387005649748 and std 0.9640657222375384\n",
      "Standardizing g-750 with mean 0.27242829870603336 and std 1.309482677791565\n",
      "Standardizing g-751 with mean 0.022007845817386535 and std 1.0261842202527278\n",
      "Standardizing g-752 with mean 0.11899434572626182 and std 1.0527890799168635\n",
      "Standardizing g-753 with mean 0.04529702934208139 and std 1.0556067381322058\n",
      "Standardizing g-754 with mean 0.09382791142700922 and std 0.8538128093182219\n",
      "Standardizing g-755 with mean -0.11680506196464366 and std 1.1840917722968602\n",
      "Standardizing g-756 with mean 0.009392714598141113 and std 0.7026762068608773\n",
      "Standardizing g-757 with mean 0.049668165664297596 and std 1.004471863968578\n",
      "Standardizing g-758 with mean 0.08551612903225843 and std 1.087163898730703\n",
      "Standardizing g-759 with mean -0.03858003918352454 and std 1.621958712105734\n",
      "Standardizing g-760 with mean -0.4431684435939523 and std 1.9716189508982387\n",
      "Standardizing g-761 with mean -0.3725225031893563 and std 1.7498598575901523\n",
      "Standardizing g-762 with mean 0.22319770821942678 and std 1.0966246994449622\n",
      "Standardizing g-763 with mean 0.006946956442500434 and std 1.2253289955747824\n",
      "Standardizing g-764 with mean 0.24450164935301621 and std 1.3581866168536632\n",
      "Standardizing g-765 with mean 0.02368972571532715 and std 1.0548563791973182\n",
      "Standardizing g-766 with mean -0.22471667122289143 and std 1.2142429169971072\n",
      "Standardizing g-767 with mean -0.060280554036814295 and std 1.128071861650506\n",
      "Standardizing g-768 with mean 0.16616405139420462 and std 0.9627301840661296\n",
      "Standardizing g-769 with mean -0.10817925551303065 and std 1.2458133910389968\n",
      "Standardizing g-770 with mean -0.25376565062875883 and std 1.350181336183213\n",
      "Standardizing g-771 with mean 0.13171093493712374 and std 1.443572224831602\n",
      "Standardizing c-0 with mean -0.39621873974849575 and std 1.8090051890914163\n",
      "Standardizing c-1 with mean -0.5105892974302904 and std 2.0660694043111874\n",
      "Standardizing c-2 with mean -0.5419688263167485 and std 2.1010621526760453\n",
      "Standardizing c-3 with mean -0.4097924229998184 and std 1.6025153544056427\n",
      "Standardizing c-4 with mean -0.5541149125205047 and std 2.1574385335391217\n",
      "Standardizing c-5 with mean -0.4981334016766917 and std 1.9513291085598823\n",
      "Standardizing c-6 with mean -0.6359983141971943 and std 2.3067880936884912\n",
      "Standardizing c-7 with mean -0.3075250364497881 and std 1.5065265397376215\n",
      "Standardizing c-8 with mean -0.5041744760342589 and std 2.0112290394637227\n",
      "Standardizing c-9 with mean -0.5014230180426453 and std 1.6960032140283212\n",
      "Standardizing c-10 with mean -0.5479166347731018 and std 2.1319902500374828\n",
      "Standardizing c-11 with mean -0.5346029569892482 and std 2.1203703949198336\n",
      "Standardizing c-12 with mean -0.5589391789684754 and std 2.210668113332863\n",
      "Standardizing c-13 with mean -0.5935135821031541 and std 2.2314111205067197\n",
      "Standardizing c-14 with mean -0.34963458629488187 and std 1.6223570852606128\n",
      "Standardizing c-15 with mean -0.4968045197740099 and std 2.038416396873329\n",
      "Standardizing c-16 with mean -0.36680583652269133 and std 1.6445499135813573\n",
      "Standardizing c-17 with mean -0.5398527656278479 and std 2.1433829926646006\n",
      "Standardizing c-18 with mean -0.6911929378531074 and std 2.359407910421368\n",
      "Standardizing c-19 with mean -0.37453519682886854 and std 1.6909837546423991\n",
      "Standardizing c-20 with mean -0.5003194550756309 and std 2.0682414413547665\n",
      "Standardizing c-21 with mean -0.5524613495534919 and std 2.087679919822774\n",
      "Standardizing c-22 with mean -0.4195323947512295 and std 1.7367876454959348\n",
      "Standardizing c-23 with mean -0.33035218243120096 and std 1.5819459826380204\n",
      "Standardizing c-24 with mean -0.5021165846546382 and std 2.0279813923178716\n",
      "Standardizing c-25 with mean -0.49811790140331563 and std 1.9599848616800812\n",
      "Standardizing c-26 with mean -0.6666274649170787 and std 2.339611883598292\n",
      "Standardizing c-27 with mean -0.49171654364862516 and std 1.974991476345931\n",
      "Standardizing c-28 with mean -0.5527725533078198 and std 1.962576261504064\n",
      "Standardizing c-29 with mean -0.33064055494805794 and std 1.5659138666849917\n",
      "Standardizing c-30 with mean -0.43460323036267345 and std 1.795060074388319\n",
      "Standardizing c-31 with mean -0.48313961636595615 and std 2.052633018812551\n",
      "Standardizing c-32 with mean -0.36853822216147236 and std 1.8284946199093317\n",
      "Standardizing c-33 with mean -0.6135254465099352 and std 2.270323349122575\n",
      "Standardizing c-34 with mean -0.512917623473664 and std 2.036612766291729\n",
      "Standardizing c-35 with mean -0.38246182795698824 and std 1.8099947752639671\n",
      "Standardizing c-36 with mean -0.5324686258429002 and std 2.0250434390497696\n",
      "Standardizing c-37 with mean -0.2429436258429022 and std 1.3209070307830977\n",
      "Standardizing c-38 with mean -0.6652189083287744 and std 2.367135270647531\n",
      "Standardizing c-39 with mean -0.4349464279205398 and std 1.9001220950977762\n",
      "Standardizing c-40 with mean -0.5409064470566777 and std 2.0555593977581084\n",
      "Standardizing c-41 with mean -0.5254153499179861 and std 2.0489891882248616\n",
      "Standardizing c-42 with mean -0.5302794833242198 and std 2.1007107010083983\n",
      "Standardizing c-43 with mean -0.5118210816475318 and std 2.0329198583512107\n",
      "Standardizing c-44 with mean -0.49199877437579725 and std 1.9938896595348539\n",
      "Standardizing c-45 with mean -0.5647432977947909 and std 2.1758869897074473\n",
      "Standardizing c-46 with mean -0.448341908146529 and std 1.851662575331054\n",
      "Standardizing c-47 with mean -0.5191738427191565 and std 1.929882106058761\n",
      "Standardizing c-48 with mean -0.5746240523054456 and std 2.0997321924471053\n",
      "Standardizing c-49 with mean -0.4345996673956632 and std 1.773852644810919\n",
      "Standardizing c-50 with mean -0.4385749772188798 and std 1.846486435849787\n",
      "Standardizing c-51 with mean -0.5224646437032996 and std 2.0222379015822254\n",
      "Standardizing c-52 with mean -0.5130572443958434 and std 2.0711255819434817\n",
      "Standardizing c-53 with mean -0.41405936303991286 and std 1.8067073207422004\n",
      "Standardizing c-54 with mean -0.4750186531802422 and std 1.8888549649450812\n",
      "Standardizing c-55 with mean -0.5471509522507738 and std 2.1867685488132413\n",
      "Standardizing c-56 with mean -0.31787469473300406 and std 1.5185994892839225\n",
      "Standardizing c-57 with mean -0.514586226535446 and std 1.9572822874192846\n",
      "Standardizing c-58 with mean -0.33113103699653806 and std 1.2690654327902937\n",
      "Standardizing c-59 with mean -0.6000853152906899 and std 2.2294905830064953\n",
      "Standardizing c-60 with mean -0.5831904228175683 and std 2.1880835207146756\n",
      "Standardizing c-61 with mean -0.40044992710042127 and std 1.7651823129160356\n",
      "Standardizing c-62 with mean -0.4710680927647141 and std 1.9606025975242278\n",
      "Standardizing c-63 with mean -0.6686315427373771 and std 2.3830914723458747\n",
      "Standardizing c-64 with mean -0.4482678786222001 and std 1.840991569228962\n",
      "Standardizing c-65 with mean -0.6868150537634393 and std 2.2978823587635246\n",
      "Standardizing c-66 with mean -0.49806431565518533 and std 2.057700453155092\n",
      "Standardizing c-67 with mean -0.5522586021505393 and std 2.1259983426508535\n",
      "Standardizing c-68 with mean -0.46410237379260044 and std 1.947147613359101\n",
      "Standardizing c-69 with mean -0.3156991434299237 and std 1.5011228462930701\n",
      "Standardizing c-70 with mean -0.6023830235101074 and std 2.2611894436246702\n",
      "Standardizing c-71 with mean -0.4028698104610902 and std 1.78441761572488\n",
      "Standardizing c-72 with mean -0.5027624749407721 and std 1.982178496941076\n",
      "Standardizing c-73 with mean -0.5553907098596642 and std 2.0765834130647187\n",
      "Standardizing c-74 with mean -0.02672454893384364 and std 1.053125857015046\n",
      "Standardizing c-75 with mean -0.5244552578822642 and std 2.066567203505649\n",
      "Standardizing c-76 with mean -0.31590341716785075 and std 1.467564008367306\n",
      "Standardizing c-77 with mean -0.5043413249498864 and std 1.9851850472338828\n",
      "Standardizing c-78 with mean -0.4639221432476753 and std 1.9482132495440847\n",
      "Standardizing c-79 with mean -0.5116006925460177 and std 1.886701561549755\n",
      "Standardizing c-80 with mean -0.5249432340076554 and std 2.0775329115907386\n",
      "Standardizing c-81 with mean -0.5653415892108605 and std 2.1515865701623804\n",
      "Standardizing c-82 with mean -0.5477119965372673 and std 2.1212247398069484\n",
      "Standardizing c-83 with mean -0.4928771778749774 and std 2.0532225859519913\n",
      "Standardizing c-84 with mean -0.5278835429196301 and std 2.07096625602614\n",
      "Standardizing c-85 with mean -0.4569161472571513 and std 1.9434387813290972\n",
      "Standardizing c-86 with mean -0.3841972343721506 and std 1.6944217006261058\n",
      "Standardizing c-87 with mean -0.32231160925825025 and std 1.6873740878755035\n",
      "Standardizing c-88 with mean -0.36318440860215073 and std 1.7147929927809449\n",
      "Standardizing c-89 with mean -0.4379961317659908 and std 1.8942891440526914\n",
      "Standardizing c-90 with mean -0.5229214005831958 and std 2.064285567446885\n",
      "Standardizing c-91 with mean -0.5118954437762006 and std 2.1102224778062713\n",
      "Standardizing c-92 with mean -0.5579920903954799 and std 2.0660651637654777\n",
      "Standardizing c-93 with mean -0.5659390377255323 and std 2.1727126819215155\n",
      "Standardizing c-94 with mean -0.5731762073993073 and std 2.225599851002027\n",
      "Standardizing c-95 with mean -0.40042610260616074 and std 1.676732490700834\n",
      "Standardizing c-96 with mean -0.5161353836340467 and std 2.1263252044068675\n",
      "Standardizing c-97 with mean -0.42414786768726165 and std 1.7532323072329212\n",
      "Standardizing c-98 with mean -0.5346234827774756 and std 1.8887036405034796\n",
      "Standardizing c-99 with mean -0.3495598915618742 and std 1.4421775831071204\n"
     ]
    }
   ],
   "source": [
    "##scaling the features,\n",
    "for col in train_features.columns[4:]:\n",
    "    mean,std=train_features[col].mean(),train_features[col].std()\n",
    "    print(f'Standardizing {col} with mean {mean} and std {std}')\n",
    "    train_features[col]=(train_features[col]-mean)/std\n",
    "    test_features[col]=(test_features[col]-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:23.393720Z",
     "iopub.status.busy": "2020-11-02T01:22:23.391615Z",
     "iopub.status.idle": "2020-11-02T01:22:23.394569Z",
     "shell.execute_reply": "2020-11-02T01:22:23.395125Z"
    },
    "papermill": {
     "duration": 0.049798,
     "end_time": "2020-11-02T01:22:23.395264",
     "exception": false,
     "start_time": "2020-11-02T01:22:23.345466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:23.476001Z",
     "iopub.status.busy": "2020-11-02T01:22:23.475245Z",
     "iopub.status.idle": "2020-11-02T01:22:23.481616Z",
     "shell.execute_reply": "2020-11-02T01:22:23.480991Z"
    },
    "papermill": {
     "duration": 0.047878,
     "end_time": "2020-11-02T01:22:23.481725",
     "exception": false,
     "start_time": "2020-11-02T01:22:23.433847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:23.559726Z",
     "iopub.status.busy": "2020-11-02T01:22:23.559057Z",
     "iopub.status.idle": "2020-11-02T01:22:23.562936Z",
     "shell.execute_reply": "2020-11-02T01:22:23.563519Z"
    },
    "papermill": {
     "duration": 0.045173,
     "end_time": "2020-11-02T01:22:23.563683",
     "exception": false,
     "start_time": "2020-11-02T01:22:23.518510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets=train_targets_scored.columns[1:]\n",
    "num_targets=len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:23.665176Z",
     "iopub.status.busy": "2020-11-02T01:22:23.661940Z",
     "iopub.status.idle": "2020-11-02T01:22:23.671850Z",
     "shell.execute_reply": "2020-11-02T01:22:23.671198Z"
    },
    "papermill": {
     "duration": 0.071687,
     "end_time": "2020-11-02T01:22:23.671969",
     "exception": false,
     "start_time": "2020-11-02T01:22:23.600282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.549586</td>\n",
       "      <td>0.794990</td>\n",
       "      <td>-0.401905</td>\n",
       "      <td>-0.735057</td>\n",
       "      <td>-0.273013</td>\n",
       "      <td>-0.734081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391962</td>\n",
       "      <td>0.365030</td>\n",
       "      <td>0.660963</td>\n",
       "      <td>0.514674</td>\n",
       "      <td>0.171628</td>\n",
       "      <td>0.631482</td>\n",
       "      <td>0.055511</td>\n",
       "      <td>0.363927</td>\n",
       "      <td>0.484313</td>\n",
       "      <td>0.531946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.142507</td>\n",
       "      <td>0.609193</td>\n",
       "      <td>0.126192</td>\n",
       "      <td>-0.021845</td>\n",
       "      <td>0.912762</td>\n",
       "      <td>0.561225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046709</td>\n",
       "      <td>0.600029</td>\n",
       "      <td>0.497948</td>\n",
       "      <td>0.271062</td>\n",
       "      <td>0.390401</td>\n",
       "      <td>0.530989</td>\n",
       "      <td>0.314315</td>\n",
       "      <td>0.312707</td>\n",
       "      <td>0.604819</td>\n",
       "      <td>0.753485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.245477</td>\n",
       "      <td>0.824916</td>\n",
       "      <td>1.337724</td>\n",
       "      <td>-0.165074</td>\n",
       "      <td>-0.114604</td>\n",
       "      <td>1.168270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097893</td>\n",
       "      <td>-0.055826</td>\n",
       "      <td>0.565467</td>\n",
       "      <td>0.270739</td>\n",
       "      <td>-0.337358</td>\n",
       "      <td>0.049517</td>\n",
       "      <td>-0.059052</td>\n",
       "      <td>0.117182</td>\n",
       "      <td>-0.462421</td>\n",
       "      <td>0.722976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.554596</td>\n",
       "      <td>-0.211053</td>\n",
       "      <td>-0.418993</td>\n",
       "      <td>0.468566</td>\n",
       "      <td>3.886483</td>\n",
       "      <td>-0.562946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763498</td>\n",
       "      <td>-0.062650</td>\n",
       "      <td>-2.454912</td>\n",
       "      <td>-0.373754</td>\n",
       "      <td>-0.130313</td>\n",
       "      <td>-0.529347</td>\n",
       "      <td>-0.519612</td>\n",
       "      <td>-0.259094</td>\n",
       "      <td>0.077844</td>\n",
       "      <td>-0.323012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.422582</td>\n",
       "      <td>-0.400341</td>\n",
       "      <td>0.773906</td>\n",
       "      <td>0.639331</td>\n",
       "      <td>1.302678</td>\n",
       "      <td>-0.575538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255353</td>\n",
       "      <td>0.244854</td>\n",
       "      <td>0.592911</td>\n",
       "      <td>0.752487</td>\n",
       "      <td>0.505696</td>\n",
       "      <td>0.058045</td>\n",
       "      <td>0.294186</td>\n",
       "      <td>0.406477</td>\n",
       "      <td>0.082609</td>\n",
       "      <td>0.736428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id cp_type  cp_time cp_dose       g-0       g-1       g-2  \\\n",
       "0  id_000644bb2  trt_cp       24      D1  0.549586  0.794990 -0.401905   \n",
       "1  id_000779bfc  trt_cp       72      D1 -0.142507  0.609193  0.126192   \n",
       "2  id_000a6266a  trt_cp       48      D1  0.245477  0.824916  1.337724   \n",
       "3  id_0015fd391  trt_cp       48      D1 -0.554596 -0.211053 -0.418993   \n",
       "4  id_001626bd3  trt_cp       72      D2 -0.422582 -0.400341  0.773906   \n",
       "\n",
       "        g-3       g-4       g-5  ...      c-90      c-91      c-92      c-93  \\\n",
       "0 -0.735057 -0.273013 -0.734081  ...  0.391962  0.365030  0.660963  0.514674   \n",
       "1 -0.021845  0.912762  0.561225  ...  0.046709  0.600029  0.497948  0.271062   \n",
       "2 -0.165074 -0.114604  1.168270  ... -0.097893 -0.055826  0.565467  0.270739   \n",
       "3  0.468566  3.886483 -0.562946  ... -0.763498 -0.062650 -2.454912 -0.373754   \n",
       "4  0.639331  1.302678 -0.575538  ...  0.255353  0.244854  0.592911  0.752487   \n",
       "\n",
       "       c-94      c-95      c-96      c-97      c-98      c-99  \n",
       "0  0.171628  0.631482  0.055511  0.363927  0.484313  0.531946  \n",
       "1  0.390401  0.530989  0.314315  0.312707  0.604819  0.753485  \n",
       "2 -0.337358  0.049517 -0.059052  0.117182 -0.462421  0.722976  \n",
       "3 -0.130313 -0.529347 -0.519612 -0.259094  0.077844 -0.323012  \n",
       "4  0.505696  0.058045  0.294186  0.406477  0.082609  0.736428  \n",
       "\n",
       "[5 rows x 876 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:23.768079Z",
     "iopub.status.busy": "2020-11-02T01:22:23.766882Z",
     "iopub.status.idle": "2020-11-02T01:22:23.904788Z",
     "shell.execute_reply": "2020-11-02T01:22:23.903791Z"
    },
    "papermill": {
     "duration": 0.190393,
     "end_time": "2020-11-02T01:22:23.904913",
     "exception": false,
     "start_time": "2020-11-02T01:22:23.714520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features=train_features[train_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test_features=test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:23.992580Z",
     "iopub.status.busy": "2020-11-02T01:22:23.991867Z",
     "iopub.status.idle": "2020-11-02T01:22:24.270824Z",
     "shell.execute_reply": "2020-11-02T01:22:24.271408Z"
    },
    "papermill": {
     "duration": 0.328778,
     "end_time": "2020-11-02T01:22:24.271575",
     "exception": false,
     "start_time": "2020-11-02T01:22:23.942797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df=pd.concat([train_features,pd.get_dummies(train_features['cp_time'],prefix='cp_time')],axis=1)\n",
    "train_df=pd.concat([train_df,pd.get_dummies(train_df['cp_type'],prefix='cp_type')],axis=1)\n",
    "train_df=pd.concat([train_df,pd.get_dummies(train_df['cp_dose'],prefix='cp_dose')],axis=1)\n",
    "train_df=train_df.drop(['cp_time','cp_type','cp_dose'],axis=1)\n",
    "\n",
    "#test features,\n",
    "test_df=pd.concat([test_features,pd.get_dummies(test_features['cp_time'],prefix='cp_time')],axis=1)\n",
    "test_df=pd.concat([test_df,pd.get_dummies(test_df['cp_type'],prefix='cp_type')],axis=1)\n",
    "test_df=pd.concat([test_df,pd.get_dummies(test_df['cp_dose'],prefix='cp_dose')],axis=1)\n",
    "test_df=test_df.drop(['cp_time','cp_type','cp_dose'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:24.404625Z",
     "iopub.status.busy": "2020-11-02T01:22:24.359519Z",
     "iopub.status.idle": "2020-11-02T01:22:24.416330Z",
     "shell.execute_reply": "2020-11-02T01:22:24.415751Z"
    },
    "papermill": {
     "duration": 0.104273,
     "end_time": "2020-11-02T01:22:24.416472",
     "exception": false,
     "start_time": "2020-11-02T01:22:24.312199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.drop('sig_id',axis=1,inplace=True)\n",
    "test_df.drop('sig_id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:24.501098Z",
     "iopub.status.busy": "2020-11-02T01:22:24.499691Z",
     "iopub.status.idle": "2020-11-02T01:22:24.503806Z",
     "shell.execute_reply": "2020-11-02T01:22:24.504329Z"
    },
    "papermill": {
     "duration": 0.049529,
     "end_time": "2020-11-02T01:22:24.504473",
     "exception": false,
     "start_time": "2020-11-02T01:22:24.454944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features=train_df.shape[1]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:24.592817Z",
     "iopub.status.busy": "2020-11-02T01:22:24.591921Z",
     "iopub.status.idle": "2020-11-02T01:22:24.594818Z",
     "shell.execute_reply": "2020-11-02T01:22:24.595273Z"
    },
    "papermill": {
     "duration": 0.051796,
     "end_time": "2020-11-02T01:22:24.595421",
     "exception": false,
     "start_time": "2020-11-02T01:22:24.543625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/166833\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            # true_dist = pred.data.clone()\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:24.679948Z",
     "iopub.status.busy": "2020-11-02T01:22:24.677940Z",
     "iopub.status.idle": "2020-11-02T01:22:24.680732Z",
     "shell.execute_reply": "2020-11-02T01:22:24.681275Z"
    },
    "papermill": {
     "duration": 0.047504,
     "end_time": "2020-11-02T01:22:24.681419",
     "exception": false,
     "start_time": "2020-11-02T01:22:24.633915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds=MultilabelStratifiedKFold(n_splits=5,shuffle=False,random_state=42)\n",
    "# train_df.loc[:,'folds']=-1\n",
    "# for i,(trn_idx,val_idx) in enumerate(folds.split(train_df,train_targets_scored[targets])):\n",
    "#     print(f'For fold {i} Train index {len(trn_idx)} Valid index {len(val_idx)}')\n",
    "#     train_df.loc[val_idx,'folds']=i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:24.772631Z",
     "iopub.status.busy": "2020-11-02T01:22:24.769219Z",
     "iopub.status.idle": "2020-11-02T01:22:24.775509Z",
     "shell.execute_reply": "2020-11-02T01:22:24.774913Z"
    },
    "papermill": {
     "duration": 0.054797,
     "end_time": "2020-11-02T01:22:24.775618",
     "exception": false,
     "start_time": "2020-11-02T01:22:24.720821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MOADataset():\n",
    "    def __init__(self,data,label):\n",
    "        self.data=data.values\n",
    "        self.label=label.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        return {\n",
    "            \"x\":torch.tensor(self.data[item,],dtype=torch.float),\n",
    "            \"y\":torch.tensor(self.label[item,],dtype=torch.float)\n",
    "        }\n",
    "    \n",
    "class MOADatasetTest():\n",
    "    def __init__(self,data):\n",
    "        self.data=data.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        return {\n",
    "            \"x\":torch.tensor(self.data[item,],dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:24.870235Z",
     "iopub.status.busy": "2020-11-02T01:22:24.869241Z",
     "iopub.status.idle": "2020-11-02T01:22:24.872625Z",
     "shell.execute_reply": "2020-11-02T01:22:24.873140Z"
    },
    "papermill": {
     "duration": 0.057414,
     "end_time": "2020-11-02T01:22:24.873285",
     "exception": false,
     "start_time": "2020-11-02T01:22:24.815871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MOAnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1=nn.Linear(num_features,2048)\n",
    "        self.bn1=nn.BatchNorm1d(2048)\n",
    "        self.do1=nn.Dropout(0.3)\n",
    "        self.l2=nn.Linear(2048,1024)\n",
    "        self.bn2=nn.BatchNorm1d(1024)\n",
    "        self.do2=nn.Dropout(0.2)\n",
    "        self.l3=nn.Linear(1024,512)\n",
    "        self.bn3=nn.BatchNorm1d(512)\n",
    "        self.do3=nn.Dropout(0.4)\n",
    "        self.out=nn.Linear(512,num_targets)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.bn1(self.l1(x))\n",
    "        x=F.relu(self.do1(x))\n",
    "        x=self.bn2(self.l2(x))\n",
    "        x=F.relu(self.do2(x))\n",
    "        x=self.bn3(self.l3(x))\n",
    "        x=F.relu(self.do3(x))\n",
    "        x=self.out(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:24.963437Z",
     "iopub.status.busy": "2020-11-02T01:22:24.961718Z",
     "iopub.status.idle": "2020-11-02T01:22:24.964156Z",
     "shell.execute_reply": "2020-11-02T01:22:24.964698Z"
    },
    "papermill": {
     "duration": 0.052552,
     "end_time": "2020-11-02T01:22:24.964848",
     "exception": false,
     "start_time": "2020-11-02T01:22:24.912296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:25.049780Z",
     "iopub.status.busy": "2020-11-02T01:22:25.048963Z",
     "iopub.status.idle": "2020-11-02T01:22:25.052912Z",
     "shell.execute_reply": "2020-11-02T01:22:25.053453Z"
    },
    "papermill": {
     "duration": 0.047765,
     "end_time": "2020-11-02T01:22:25.053622",
     "exception": false,
     "start_time": "2020-11-02T01:22:25.005857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_x,valid_x,train_tar,valid_tar=train_test_split(train_df,train_targets_scored.loc[:,targets],test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:25.137158Z",
     "iopub.status.busy": "2020-11-02T01:22:25.136461Z",
     "iopub.status.idle": "2020-11-02T01:22:25.140941Z",
     "shell.execute_reply": "2020-11-02T01:22:25.140389Z"
    },
    "papermill": {
     "duration": 0.047928,
     "end_time": "2020-11-02T01:22:25.141067",
     "exception": false,
     "start_time": "2020-11-02T01:22:25.093139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_tar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:25.228639Z",
     "iopub.status.busy": "2020-11-02T01:22:25.226475Z",
     "iopub.status.idle": "2020-11-02T01:22:25.229438Z",
     "shell.execute_reply": "2020-11-02T01:22:25.230047Z"
    },
    "papermill": {
     "duration": 0.04912,
     "end_time": "2020-11-02T01:22:25.230189",
     "exception": false,
     "start_time": "2020-11-02T01:22:25.181069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:25.315595Z",
     "iopub.status.busy": "2020-11-02T01:22:25.314801Z",
     "iopub.status.idle": "2020-11-02T01:22:25.319630Z",
     "shell.execute_reply": "2020-11-02T01:22:25.318992Z"
    },
    "papermill": {
     "duration": 0.050082,
     "end_time": "2020-11-02T01:22:25.319747",
     "exception": false,
     "start_time": "2020-11-02T01:22:25.269665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset=MOADataset(data=train_x.values,\n",
    "#                         label=train_tar.values)\n",
    "# train_dataloader=DataLoader(train_dataset,batch_size=1024,shuffle=True,num_workers=4)\n",
    "# valid_dataset=MOADataset(data=valid_x.values,\n",
    "#                         label=valid_tar.values)\n",
    "# valid_dataloader=DataLoader(valid_dataset,batch_size=1024,shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:25.408146Z",
     "iopub.status.busy": "2020-11-02T01:22:25.407396Z",
     "iopub.status.idle": "2020-11-02T01:22:25.411408Z",
     "shell.execute_reply": "2020-11-02T01:22:25.410794Z"
    },
    "papermill": {
     "duration": 0.048723,
     "end_time": "2020-11-02T01:22:25.411521",
     "exception": false,
     "start_time": "2020-11-02T01:22:25.362798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/ateplyuk/aptos-pytorch-starter-rnet50\n",
    "#https://www.kaggle.com/chanhu/eye-inference-num-class-1-ver3\n",
    "#https://www.kaggle.com/chanhu/eye-efficientnet-pytorch-lb-0-777\n",
    "#https://www.kaggle.com/artgor/basic-eda-and-baseline-pytorch-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:25.499910Z",
     "iopub.status.busy": "2020-11-02T01:22:25.499011Z",
     "iopub.status.idle": "2020-11-02T01:22:30.178292Z",
     "shell.execute_reply": "2020-11-02T01:22:30.177037Z"
    },
    "papermill": {
     "duration": 4.726591,
     "end_time": "2020-11-02T01:22:30.178438",
     "exception": false,
     "start_time": "2020-11-02T01:22:25.451847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=MOAnn()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "scheduler=lr_scheduler.StepLR(optimizer,step_size=10)\n",
    "criterion=nn.BCEWithLogitsLoss()\n",
    "#criterion=LabelSmoothingLoss()\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:30.284252Z",
     "iopub.status.busy": "2020-11-02T01:22:30.283052Z",
     "iopub.status.idle": "2020-11-02T01:22:30.290225Z",
     "shell.execute_reply": "2020-11-02T01:22:30.289635Z"
    },
    "papermill": {
     "duration": 0.071499,
     "end_time": "2020-11-02T01:22:30.290344",
     "exception": false,
     "start_time": "2020-11-02T01:22:30.218845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_folds(fold,trn_x,trn_y,val_x,val_y,NUM_EPOCHS):\n",
    "    print('-'*10)\n",
    "    print(f'Running fold {fold+1}')\n",
    "    best_loss=np.Inf\n",
    "    train_dataset=MOADataset(data=trn_x,\n",
    "                            label=trn_y)\n",
    "    train_dataloader=DataLoader(train_dataset,batch_size=1024,shuffle=True)\n",
    "    print(len(train_dataloader))\n",
    "    valid_dataset=MOADataset(data=val_x,\n",
    "                            label=val_y)\n",
    "    valid_dataloader=DataLoader(valid_dataset,batch_size=1024,shuffle=True)\n",
    "    test_dataset=MOADatasetTest(data=test_df)\n",
    "    test_dataloader=DataLoader(test_dataset,batch_size=1024,shuffle=False,num_workers=4)\n",
    "    test_preds=np.zeros((len(test_dataset),num_targets))\n",
    "    print(len(valid_dataloader))\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        counter=0\n",
    "        avg_tr_loss=0.0\n",
    "        model.train()\n",
    "        for bi,d in enumerate(train_dataloader):\n",
    "            inputs=d['x']\n",
    "            labels=d['y']\n",
    "            inputs=inputs.to(device,dtype=torch.float)\n",
    "            labels=labels.to(device,dtype=torch.float)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(True):\n",
    "                output=model(inputs)\n",
    "                loss=criterion(output,labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            avg_tr_loss+=loss.item() /len(train_dataloader)\n",
    "\n",
    "        #print(f'Epoch {epoch+1} ')\n",
    "\n",
    "        model.eval()\n",
    "        avg_val_loss=0.0\n",
    "        val_preds=[]\n",
    "        for bi,d in enumerate(valid_dataloader):\n",
    "            inputs=d['x']\n",
    "            labels=d['y']\n",
    "            inputs=inputs.to(device,dtype=torch.float)\n",
    "            labels=labels.to(device,dtype=torch.float)\n",
    "            with torch.no_grad():\n",
    "                output=model(inputs)\n",
    "            #print(type(val_output))\n",
    "            loss=criterion(output,labels)\n",
    "            avg_val_loss+=loss.item() /len(valid_dataloader)\n",
    "            scheduler.step()\n",
    "            val_output=torch.sigmoid(output).detach().cpu().squeeze().numpy()\n",
    "            \n",
    "            #print(f'Val Output {type(val_output)} and {val_output} and {val_output.shape}')\n",
    "            val_preds.append(val_output)\n",
    "            #print(f'Val preds {val_preds}')\n",
    "            #print(f'Validation prediction shape after appending {len(val_preds)}')\n",
    "        print(f'Epoch {epoch+1}  Training epoch Loss {avg_tr_loss} Validation epoch Loss {avg_val_loss}')\n",
    "        val_preds=np.concatenate(val_preds)\n",
    "        #print(f'Validation prediction shape after concatenating {val_preds.shape}')\n",
    "        \n",
    "\n",
    "        if avg_val_loss < best_loss:\n",
    "            print(f'Validation loss {avg_val_loss} is less than best loss {best_loss}.Saving the model')\n",
    "            torch.save(model.state_dict(),f'model_{fold}.bin')\n",
    "            best_loss=avg_val_loss\n",
    "        \n",
    "    model.load_state_dict(torch.load(f'model_{fold}.bin'))\n",
    "  \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for bi,d in enumerate(test_dataloader):\n",
    "            inputs=d['x']\n",
    "            inputs=inputs.to(device,dtype=torch.float)\n",
    "            pred=model(inputs)\n",
    "            #print(pred,pred.shape,torch.sigmoid(pred),pred.detach().cpu().sqeeze())\n",
    "            test_preds[bi*1024:(bi+1)*1024]=torch.sigmoid(pred).detach().cpu().squeeze().numpy().ravel().reshape(-1,206)\n",
    "            #print(type(test_preds))\n",
    "    \n",
    "    return val_preds,test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:22:30.384915Z",
     "iopub.status.busy": "2020-11-02T01:22:30.383960Z",
     "iopub.status.idle": "2020-11-02T01:25:05.380016Z",
     "shell.execute_reply": "2020-11-02T01:25:05.378436Z"
    },
    "papermill": {
     "duration": 155.046618,
     "end_time": "2020-11-02T01:25:05.380166",
     "exception": false,
     "start_time": "2020-11-02T01:22:30.333548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1\n",
      "(17558, 878) (4390, 878) (17558, 206) (4390, 206)\n",
      "----------\n",
      "Running fold 1\n",
      "18\n",
      "5\n",
      "Epoch 1  Training epoch Loss 0.26939278489185703 Validation epoch Loss 0.11208584159612656\n",
      "Validation loss 0.11208584159612656 is less than best loss inf.Saving the model\n",
      "Epoch 2  Training epoch Loss 0.03273369972076681 Validation epoch Loss 0.024864024296402932\n",
      "Validation loss 0.024864024296402932 is less than best loss 0.11208584159612656.Saving the model\n",
      "Epoch 3  Training epoch Loss 0.02453139579544465 Validation epoch Loss 0.02371789924800396\n",
      "Validation loss 0.02371789924800396 is less than best loss 0.024864024296402932.Saving the model\n",
      "Epoch 4  Training epoch Loss 0.02420410524225897 Validation epoch Loss 0.02341998890042305\n",
      "Validation loss 0.02341998890042305 is less than best loss 0.02371789924800396.Saving the model\n",
      "Epoch 5  Training epoch Loss 0.023999758685628567 Validation epoch Loss 0.023426663130521774\n",
      "Epoch 6  Training epoch Loss 0.024073860608041283 Validation epoch Loss 0.02318359576165676\n",
      "Validation loss 0.02318359576165676 is less than best loss 0.02341998890042305.Saving the model\n",
      "Epoch 7  Training epoch Loss 0.023857844683031246 Validation epoch Loss 0.02333743199706078\n",
      "Epoch 8  Training epoch Loss 0.024013838730752465 Validation epoch Loss 0.023218202963471414\n",
      "Epoch 9  Training epoch Loss 0.023987190797924995 Validation epoch Loss 0.02347888574004173\n",
      "Epoch 10  Training epoch Loss 0.02402189146313402 Validation epoch Loss 0.02331100106239319\n",
      "Epoch 11  Training epoch Loss 0.024051031097769737 Validation epoch Loss 0.02322958707809448\n",
      "Epoch 12  Training epoch Loss 0.02396695440014203 Validation epoch Loss 0.023298522084951402\n",
      "Epoch 13  Training epoch Loss 0.0239934449394544 Validation epoch Loss 0.02333872988820076\n",
      "Epoch 14  Training epoch Loss 0.02405540748602814 Validation epoch Loss 0.023266375437378882\n",
      "Epoch 15  Training epoch Loss 0.023949668639236022 Validation epoch Loss 0.02343624383211136\n",
      "Epoch 16  Training epoch Loss 0.023956943717267774 Validation epoch Loss 0.023091723769903184\n",
      "Validation loss 0.023091723769903184 is less than best loss 0.02318359576165676.Saving the model\n",
      "Epoch 17  Training epoch Loss 0.023830896967815027 Validation epoch Loss 0.02327226512134075\n",
      "Epoch 18  Training epoch Loss 0.0240701399743557 Validation epoch Loss 0.023391829431056978\n",
      "Epoch 19  Training epoch Loss 0.023961012872556847 Validation epoch Loss 0.023309094831347466\n",
      "Epoch 20  Training epoch Loss 0.02407316346135404 Validation epoch Loss 0.023390649259090422\n",
      "Epoch 21  Training epoch Loss 0.023981198047598202 Validation epoch Loss 0.023434965685009957\n",
      "Epoch 22  Training epoch Loss 0.023935446101758216 Validation epoch Loss 0.02340078428387642\n",
      "Epoch 23  Training epoch Loss 0.02391984955304199 Validation epoch Loss 0.023296219855546953\n",
      "Epoch 24  Training epoch Loss 0.023962179509301976 Validation epoch Loss 0.023306741565465926\n",
      "Epoch 25  Training epoch Loss 0.02400382546087106 Validation epoch Loss 0.023058974742889406\n",
      "Validation loss 0.023058974742889406 is less than best loss 0.023091723769903184.Saving the model\n",
      "Epoch 26  Training epoch Loss 0.024002767064505156 Validation epoch Loss 0.02315966971218586\n",
      "Epoch 27  Training epoch Loss 0.023954994873040255 Validation epoch Loss 0.023541265353560447\n",
      "Epoch 28  Training epoch Loss 0.02399317392458518 Validation epoch Loss 0.023153328150510785\n",
      "Epoch 29  Training epoch Loss 0.02400404866784811 Validation epoch Loss 0.02330760136246681\n",
      "Epoch 30  Training epoch Loss 0.024043622530168958 Validation epoch Loss 0.023356583341956137\n",
      "Starting fold 2\n",
      "(17559, 878) (4389, 878) (17559, 206) (4389, 206)\n",
      "----------\n",
      "Running fold 2\n",
      "18\n",
      "5\n",
      "Epoch 1  Training epoch Loss 0.024032344006829794 Validation epoch Loss 0.023191579431295392\n",
      "Validation loss 0.023191579431295392 is less than best loss inf.Saving the model\n",
      "Epoch 2  Training epoch Loss 0.023828162501255676 Validation epoch Loss 0.023182537034153936\n",
      "Validation loss 0.023182537034153936 is less than best loss 0.023191579431295392.Saving the model\n",
      "Epoch 3  Training epoch Loss 0.02402258591933383 Validation epoch Loss 0.023220751062035562\n",
      "Epoch 4  Training epoch Loss 0.024011224197844665 Validation epoch Loss 0.02334663905203342\n",
      "Epoch 5  Training epoch Loss 0.023984264685875844 Validation epoch Loss 0.023278848081827164\n",
      "Epoch 6  Training epoch Loss 0.024107005447149277 Validation epoch Loss 0.023340104892849923\n",
      "Epoch 7  Training epoch Loss 0.02415231315212117 Validation epoch Loss 0.02338589318096638\n",
      "Epoch 8  Training epoch Loss 0.023950815614726804 Validation epoch Loss 0.023343561589717864\n",
      "Epoch 9  Training epoch Loss 0.023914455125729244 Validation epoch Loss 0.023113053292036057\n",
      "Validation loss 0.023113053292036057 is less than best loss 0.023182537034153936.Saving the model\n",
      "Epoch 10  Training epoch Loss 0.02404345033897294 Validation epoch Loss 0.023540399968624115\n",
      "Epoch 11  Training epoch Loss 0.024035567521221105 Validation epoch Loss 0.02334540747106075\n",
      "Epoch 12  Training epoch Loss 0.024006493286126192 Validation epoch Loss 0.023428143933415413\n",
      "Epoch 13  Training epoch Loss 0.02406097306973404 Validation epoch Loss 0.023125297203660015\n",
      "Epoch 14  Training epoch Loss 0.02404772842095957 Validation epoch Loss 0.023308419436216355\n",
      "Epoch 15  Training epoch Loss 0.023903051080803074 Validation epoch Loss 0.023039691522717478\n",
      "Validation loss 0.023039691522717478 is less than best loss 0.023113053292036057.Saving the model\n",
      "Epoch 16  Training epoch Loss 0.024031114661031302 Validation epoch Loss 0.02316270247101784\n",
      "Epoch 17  Training epoch Loss 0.02392899007019069 Validation epoch Loss 0.02318492382764816\n",
      "Epoch 18  Training epoch Loss 0.023983406420383182 Validation epoch Loss 0.02334499768912792\n",
      "Epoch 19  Training epoch Loss 0.02404459203696913 Validation epoch Loss 0.023259186744689943\n",
      "Epoch 20  Training epoch Loss 0.024122090803252325 Validation epoch Loss 0.023235011845827103\n",
      "Epoch 21  Training epoch Loss 0.023955265267027744 Validation epoch Loss 0.02326105907559395\n",
      "Epoch 22  Training epoch Loss 0.023926621406442587 Validation epoch Loss 0.02320277690887451\n",
      "Epoch 23  Training epoch Loss 0.023993188411825232 Validation epoch Loss 0.023321925848722457\n",
      "Epoch 24  Training epoch Loss 0.0240155996547805 Validation epoch Loss 0.023242591693997387\n",
      "Epoch 25  Training epoch Loss 0.023936067500876058 Validation epoch Loss 0.0231777410954237\n",
      "Epoch 26  Training epoch Loss 0.02397130119303862 Validation epoch Loss 0.02326187752187252\n",
      "Epoch 27  Training epoch Loss 0.024129615993135508 Validation epoch Loss 0.023043815791606904\n",
      "Epoch 28  Training epoch Loss 0.024012412565449875 Validation epoch Loss 0.0231575645506382\n",
      "Epoch 29  Training epoch Loss 0.02395082451403141 Validation epoch Loss 0.02316353693604469\n",
      "Epoch 30  Training epoch Loss 0.024043994231356516 Validation epoch Loss 0.02344224452972412\n",
      "Starting fold 3\n",
      "(17558, 878) (4390, 878) (17558, 206) (4390, 206)\n",
      "----------\n",
      "Running fold 3\n",
      "18\n",
      "5\n",
      "Epoch 1  Training epoch Loss 0.023952106013894078 Validation epoch Loss 0.02331502661108971\n",
      "Validation loss 0.02331502661108971 is less than best loss inf.Saving the model\n",
      "Epoch 2  Training epoch Loss 0.02402625729640325 Validation epoch Loss 0.02311435267329216\n",
      "Validation loss 0.02311435267329216 is less than best loss 0.02331502661108971.Saving the model\n",
      "Epoch 3  Training epoch Loss 0.02397789619863033 Validation epoch Loss 0.02317558079957962\n",
      "Epoch 4  Training epoch Loss 0.024042712421052985 Validation epoch Loss 0.023102430626749992\n",
      "Validation loss 0.023102430626749992 is less than best loss 0.02311435267329216.Saving the model\n",
      "Epoch 5  Training epoch Loss 0.024034304544329643 Validation epoch Loss 0.023152196407318117\n",
      "Epoch 6  Training epoch Loss 0.024042688310146325 Validation epoch Loss 0.02320835813879967\n",
      "Epoch 7  Training epoch Loss 0.02405178019156058 Validation epoch Loss 0.02325577512383461\n",
      "Epoch 8  Training epoch Loss 0.023999130146370996 Validation epoch Loss 0.02340801581740379\n",
      "Epoch 9  Training epoch Loss 0.024010713419152632 Validation epoch Loss 0.02308443859219551\n",
      "Validation loss 0.02308443859219551 is less than best loss 0.023102430626749992.Saving the model\n",
      "Epoch 10  Training epoch Loss 0.024001733710368477 Validation epoch Loss 0.023142317682504656\n",
      "Epoch 11  Training epoch Loss 0.023993533001177843 Validation epoch Loss 0.023233921825885774\n",
      "Epoch 12  Training epoch Loss 0.024068786969615355 Validation epoch Loss 0.02314766235649586\n",
      "Epoch 13  Training epoch Loss 0.02401980436924431 Validation epoch Loss 0.023120186850428583\n",
      "Epoch 14  Training epoch Loss 0.02397027953217427 Validation epoch Loss 0.023393182456493376\n",
      "Epoch 15  Training epoch Loss 0.024150017028053607 Validation epoch Loss 0.023205161094665527\n",
      "Epoch 16  Training epoch Loss 0.024054327462282442 Validation epoch Loss 0.0229647621512413\n",
      "Validation loss 0.0229647621512413 is less than best loss 0.02308443859219551.Saving the model\n",
      "Epoch 17  Training epoch Loss 0.02393823189453946 Validation epoch Loss 0.02321719340980053\n",
      "Epoch 18  Training epoch Loss 0.024069617916312482 Validation epoch Loss 0.023162929341197014\n",
      "Epoch 19  Training epoch Loss 0.024044982571568757 Validation epoch Loss 0.023170698434114456\n",
      "Epoch 20  Training epoch Loss 0.024033878205551043 Validation epoch Loss 0.02318669334053993\n",
      "Epoch 21  Training epoch Loss 0.02404815827806791 Validation epoch Loss 0.023294931650161742\n",
      "Epoch 22  Training epoch Loss 0.024102430790662766 Validation epoch Loss 0.023043670505285264\n",
      "Epoch 23  Training epoch Loss 0.024011460132896904 Validation epoch Loss 0.02298133559525013\n",
      "Epoch 24  Training epoch Loss 0.02397566319753726 Validation epoch Loss 0.02339514158666134\n",
      "Epoch 25  Training epoch Loss 0.0239673951226804 Validation epoch Loss 0.023136673495173454\n",
      "Epoch 26  Training epoch Loss 0.024011266935202804 Validation epoch Loss 0.023057173565030096\n",
      "Epoch 27  Training epoch Loss 0.0240052015417152 Validation epoch Loss 0.023127532005310057\n",
      "Epoch 28  Training epoch Loss 0.02404670458700922 Validation epoch Loss 0.023156885802745816\n",
      "Epoch 29  Training epoch Loss 0.024082641013794474 Validation epoch Loss 0.02301058694720268\n",
      "Epoch 30  Training epoch Loss 0.024039925179547735 Validation epoch Loss 0.02290204130113125\n",
      "Validation loss 0.02290204130113125 is less than best loss 0.0229647621512413.Saving the model\n",
      "Starting fold 4\n",
      "(17558, 878) (4390, 878) (17558, 206) (4390, 206)\n",
      "----------\n",
      "Running fold 4\n",
      "18\n",
      "5\n",
      "Epoch 1  Training epoch Loss 0.024086817064219054 Validation epoch Loss 0.023252359405159947\n",
      "Validation loss 0.023252359405159947 is less than best loss inf.Saving the model\n",
      "Epoch 2  Training epoch Loss 0.023934272738794487 Validation epoch Loss 0.02332965210080147\n",
      "Epoch 3  Training epoch Loss 0.023951034268571272 Validation epoch Loss 0.023178919777274133\n",
      "Validation loss 0.023178919777274133 is less than best loss 0.023252359405159947.Saving the model\n",
      "Epoch 4  Training epoch Loss 0.02410096199148231 Validation epoch Loss 0.023323561623692514\n",
      "Epoch 5  Training epoch Loss 0.023998487119873364 Validation epoch Loss 0.023177141323685646\n",
      "Validation loss 0.023177141323685646 is less than best loss 0.023178919777274133.Saving the model\n",
      "Epoch 6  Training epoch Loss 0.023961333661443658 Validation epoch Loss 0.023441961035132408\n",
      "Epoch 7  Training epoch Loss 0.023967154841456145 Validation epoch Loss 0.02312810719013214\n",
      "Validation loss 0.02312810719013214 is less than best loss 0.023177141323685646.Saving the model\n",
      "Epoch 8  Training epoch Loss 0.02396613638848067 Validation epoch Loss 0.023170981928706168\n",
      "Epoch 9  Training epoch Loss 0.023887412829531558 Validation epoch Loss 0.023324485123157504\n",
      "Epoch 10  Training epoch Loss 0.02397421778490146 Validation epoch Loss 0.023343488201498983\n",
      "Epoch 11  Training epoch Loss 0.023953155614435673 Validation epoch Loss 0.02317211888730526\n",
      "Epoch 12  Training epoch Loss 0.02412395520756642 Validation epoch Loss 0.022975550964474678\n",
      "Validation loss 0.022975550964474678 is less than best loss 0.02312810719013214.Saving the model\n",
      "Epoch 13  Training epoch Loss 0.023962417203519076 Validation epoch Loss 0.023125094920396803\n",
      "Epoch 14  Training epoch Loss 0.024032158984078306 Validation epoch Loss 0.02320283055305481\n",
      "Epoch 15  Training epoch Loss 0.02399244707905584 Validation epoch Loss 0.023150968551635745\n",
      "Epoch 16  Training epoch Loss 0.02396702590501971 Validation epoch Loss 0.022978509217500685\n",
      "Epoch 17  Training epoch Loss 0.02402657415303919 Validation epoch Loss 0.022907250747084617\n",
      "Validation loss 0.022907250747084617 is less than best loss 0.022975550964474678.Saving the model\n",
      "Epoch 18  Training epoch Loss 0.024027894458009135 Validation epoch Loss 0.023120157420635223\n",
      "Epoch 19  Training epoch Loss 0.024047049072881535 Validation epoch Loss 0.02323942445218563\n",
      "Epoch 20  Training epoch Loss 0.024071683900223836 Validation epoch Loss 0.02331812456250191\n",
      "Epoch 21  Training epoch Loss 0.024034470837149356 Validation epoch Loss 0.023253322392702103\n",
      "Epoch 22  Training epoch Loss 0.023952508034805458 Validation epoch Loss 0.02323051393032074\n",
      "Epoch 23  Training epoch Loss 0.02397429022110171 Validation epoch Loss 0.023232572898268702\n",
      "Epoch 24  Training epoch Loss 0.024042225132385887 Validation epoch Loss 0.02346723563969135\n",
      "Epoch 25  Training epoch Loss 0.023984256200492386 Validation epoch Loss 0.023252987861633302\n",
      "Epoch 26  Training epoch Loss 0.023949522214631237 Validation epoch Loss 0.023231519013643266\n",
      "Epoch 27  Training epoch Loss 0.0240239275412427 Validation epoch Loss 0.023297753557562827\n",
      "Epoch 28  Training epoch Loss 0.024099245563977294 Validation epoch Loss 0.02319338545203209\n",
      "Epoch 29  Training epoch Loss 0.023957509443991713 Validation epoch Loss 0.023303825035691263\n",
      "Epoch 30  Training epoch Loss 0.023998741577896807 Validation epoch Loss 0.023148095235228542\n",
      "Starting fold 5\n",
      "(17559, 878) (4389, 878) (17559, 206) (4389, 206)\n",
      "----------\n",
      "Running fold 5\n",
      "18\n",
      "5\n",
      "Epoch 1  Training epoch Loss 0.02402985064933697 Validation epoch Loss 0.023161010071635246\n",
      "Validation loss 0.023161010071635246 is less than best loss inf.Saving the model\n",
      "Epoch 2  Training epoch Loss 0.024043616010910936 Validation epoch Loss 0.023178320750594138\n",
      "Epoch 3  Training epoch Loss 0.023965994620488755 Validation epoch Loss 0.02315349392592907\n",
      "Validation loss 0.02315349392592907 is less than best loss 0.023161010071635246.Saving the model\n",
      "Epoch 4  Training epoch Loss 0.024013100191950798 Validation epoch Loss 0.023306015133857726\n",
      "Epoch 5  Training epoch Loss 0.02393966375125779 Validation epoch Loss 0.023194007948040964\n",
      "Epoch 6  Training epoch Loss 0.024093790704177484 Validation epoch Loss 0.023197896778583523\n",
      "Epoch 7  Training epoch Loss 0.02399323259790738 Validation epoch Loss 0.023359157145023346\n",
      "Epoch 8  Training epoch Loss 0.02396707226418787 Validation epoch Loss 0.023229736089706417\n",
      "Epoch 9  Training epoch Loss 0.024074009205732078 Validation epoch Loss 0.023265409842133523\n",
      "Epoch 10  Training epoch Loss 0.02399082161072227 Validation epoch Loss 0.023389746993780137\n",
      "Epoch 11  Training epoch Loss 0.024021637315551438 Validation epoch Loss 0.02326740100979805\n",
      "Epoch 12  Training epoch Loss 0.02398701933109098 Validation epoch Loss 0.02338082157075405\n",
      "Epoch 13  Training epoch Loss 0.023976212988297146 Validation epoch Loss 0.02324981316924095\n",
      "Epoch 14  Training epoch Loss 0.02405564093755351 Validation epoch Loss 0.023231658339500427\n",
      "Epoch 15  Training epoch Loss 0.02396370335999462 Validation epoch Loss 0.02332313694059849\n",
      "Epoch 16  Training epoch Loss 0.024039221410122182 Validation epoch Loss 0.023094383627176286\n",
      "Validation loss 0.023094383627176286 is less than best loss 0.02315349392592907.Saving the model\n",
      "Epoch 17  Training epoch Loss 0.023877760809328824 Validation epoch Loss 0.023360028117895126\n",
      "Epoch 18  Training epoch Loss 0.024041120066410966 Validation epoch Loss 0.023304465785622598\n",
      "Epoch 19  Training epoch Loss 0.023982438983188737 Validation epoch Loss 0.023193197697401045\n",
      "Epoch 20  Training epoch Loss 0.02400380755878157 Validation epoch Loss 0.023279768973588945\n",
      "Epoch 21  Training epoch Loss 0.02401357785695129 Validation epoch Loss 0.02337757162749767\n",
      "Epoch 22  Training epoch Loss 0.02397508401837614 Validation epoch Loss 0.023095330223441124\n",
      "Epoch 23  Training epoch Loss 0.023971438407897953 Validation epoch Loss 0.023137424141168598\n",
      "Epoch 24  Training epoch Loss 0.02398032881319523 Validation epoch Loss 0.023163161054253575\n",
      "Epoch 25  Training epoch Loss 0.023995987139642242 Validation epoch Loss 0.023236320912837984\n",
      "Epoch 26  Training epoch Loss 0.02401543501764536 Validation epoch Loss 0.023071588948369026\n",
      "Validation loss 0.023071588948369026 is less than best loss 0.023094383627176286.Saving the model\n",
      "Epoch 27  Training epoch Loss 0.024103862647381093 Validation epoch Loss 0.0233508862555027\n",
      "Epoch 28  Training epoch Loss 0.023959093002809427 Validation epoch Loss 0.023308262974023816\n",
      "Epoch 29  Training epoch Loss 0.024021258991625574 Validation epoch Loss 0.023262191191315652\n",
      "Epoch 30  Training epoch Loss 0.02406123301221265 Validation epoch Loss 0.023200849443674086\n"
     ]
    }
   ],
   "source": [
    "oof=np.zeros((len(train_df),num_targets))\n",
    "prediction=np.zeros((len(test_df),num_targets))\n",
    "for i,(trn_idx,val_idx) in enumerate(folds.split(train_df,train_targets_scored[targets])):\n",
    "    print(f'Starting fold {i+1}')\n",
    "    trn_x,val_x=train_df.loc[trn_idx].reset_index(drop=True),train_df.loc[val_idx].reset_index(drop=True)\n",
    "    trn_y,val_y=train_targets_scored.iloc[trn_idx,1:].reset_index(drop=True),train_targets_scored.iloc[val_idx,1:].reset_index(drop=True)\n",
    "    print(trn_x.shape,val_x.shape,trn_y.shape,val_y.shape)\n",
    "    op,test_predictions=run_folds(i,trn_x,trn_y,val_x,val_y,30)\n",
    "    oof[val_idx]=op\n",
    "    prediction+=test_predictions/5\n",
    "#     print(f'Fold {i+1} completed')\n",
    "#     print('_'*10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:25:05.590822Z",
     "iopub.status.busy": "2020-11-02T01:25:05.589563Z",
     "iopub.status.idle": "2020-11-02T01:25:05.594752Z",
     "shell.execute_reply": "2020-11-02T01:25:05.594166Z"
    },
    "papermill": {
     "duration": 0.110621,
     "end_time": "2020-11-02T01:25:05.594868",
     "exception": false,
     "start_time": "2020-11-02T01:25:05.484247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00608028, 0.0059279 , 0.00993256, ..., 0.00729524, 0.00609187,\n",
       "       0.00770447])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:25:05.808060Z",
     "iopub.status.busy": "2020-11-02T01:25:05.807137Z",
     "iopub.status.idle": "2020-11-02T01:25:05.812400Z",
     "shell.execute_reply": "2020-11-02T01:25:05.811879Z"
    },
    "papermill": {
     "duration": 0.110322,
     "end_time": "2020-11-02T01:25:05.812501",
     "exception": false,
     "start_time": "2020-11-02T01:25:05.702179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_targets_scored.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:25:06.018451Z",
     "iopub.status.busy": "2020-11-02T01:25:06.017435Z",
     "iopub.status.idle": "2020-11-02T01:25:07.043922Z",
     "shell.execute_reply": "2020-11-02T01:25:07.044758Z"
    },
    "papermill": {
     "duration": 1.134118,
     "end_time": "2020-11-02T01:25:07.044959",
     "exception": false,
     "start_time": "2020-11-02T01:25:05.910841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025417947493155627\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/yasufuminakama/moa-pytorch-nn-starter\n",
    "score=0\n",
    "for i in range(len(targets)):\n",
    "    oof_loss=log_loss(train_targets_scored.iloc[:,i+1],oof[:,i])\n",
    "    score+=oof_loss/206\n",
    "print(f'{score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:25:07.429655Z",
     "iopub.status.busy": "2020-11-02T01:25:07.428602Z",
     "iopub.status.idle": "2020-11-02T01:25:07.433725Z",
     "shell.execute_reply": "2020-11-02T01:25:07.435191Z"
    },
    "papermill": {
     "duration": 0.178656,
     "end_time": "2020-11-02T01:25:07.435398",
     "exception": false,
     "start_time": "2020-11-02T01:25:07.256742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3624, 206)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:25:07.749727Z",
     "iopub.status.busy": "2020-11-02T01:25:07.748735Z",
     "iopub.status.idle": "2020-11-02T01:25:07.813067Z",
     "shell.execute_reply": "2020-11-02T01:25:07.814419Z"
    },
    "papermill": {
     "duration": 0.23047,
     "end_time": "2020-11-02T01:25:07.814677",
     "exception": false,
     "start_time": "2020-11-02T01:25:07.584207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3624 rows Ã— 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n",
       "0                             0.5                     0.5             0.5   \n",
       "1                             0.5                     0.5             0.5   \n",
       "3                             0.5                     0.5             0.5   \n",
       "4                             0.5                     0.5             0.5   \n",
       "6                             0.5                     0.5             0.5   \n",
       "...                           ...                     ...             ...   \n",
       "3977                          0.5                     0.5             0.5   \n",
       "3978                          0.5                     0.5             0.5   \n",
       "3979                          0.5                     0.5             0.5   \n",
       "3980                          0.5                     0.5             0.5   \n",
       "3981                          0.5                     0.5             0.5   \n",
       "\n",
       "      acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n",
       "0                                0.5                                0.5   \n",
       "1                                0.5                                0.5   \n",
       "3                                0.5                                0.5   \n",
       "4                                0.5                                0.5   \n",
       "6                                0.5                                0.5   \n",
       "...                              ...                                ...   \n",
       "3977                             0.5                                0.5   \n",
       "3978                             0.5                                0.5   \n",
       "3979                             0.5                                0.5   \n",
       "3980                             0.5                                0.5   \n",
       "3981                             0.5                                0.5   \n",
       "\n",
       "      acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n",
       "0                                0.5                         0.5   \n",
       "1                                0.5                         0.5   \n",
       "3                                0.5                         0.5   \n",
       "4                                0.5                         0.5   \n",
       "6                                0.5                         0.5   \n",
       "...                              ...                         ...   \n",
       "3977                             0.5                         0.5   \n",
       "3978                             0.5                         0.5   \n",
       "3979                             0.5                         0.5   \n",
       "3980                             0.5                         0.5   \n",
       "3981                             0.5                         0.5   \n",
       "\n",
       "      adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n",
       "0                               0.5                         0.5   \n",
       "1                               0.5                         0.5   \n",
       "3                               0.5                         0.5   \n",
       "4                               0.5                         0.5   \n",
       "6                               0.5                         0.5   \n",
       "...                             ...                         ...   \n",
       "3977                            0.5                         0.5   \n",
       "3978                            0.5                         0.5   \n",
       "3979                            0.5                         0.5   \n",
       "3980                            0.5                         0.5   \n",
       "3981                            0.5                         0.5   \n",
       "\n",
       "      adrenergic_receptor_agonist  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                             0.5  ...                                    0.5   \n",
       "1                             0.5  ...                                    0.5   \n",
       "3                             0.5  ...                                    0.5   \n",
       "4                             0.5  ...                                    0.5   \n",
       "6                             0.5  ...                                    0.5   \n",
       "...                           ...  ...                                    ...   \n",
       "3977                          0.5  ...                                    0.5   \n",
       "3978                          0.5  ...                                    0.5   \n",
       "3979                          0.5  ...                                    0.5   \n",
       "3980                          0.5  ...                                    0.5   \n",
       "3981                          0.5  ...                                    0.5   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0              0.5              0.5                0.5   \n",
       "1              0.5              0.5                0.5   \n",
       "3              0.5              0.5                0.5   \n",
       "4              0.5              0.5                0.5   \n",
       "6              0.5              0.5                0.5   \n",
       "...            ...              ...                ...   \n",
       "3977           0.5              0.5                0.5   \n",
       "3978           0.5              0.5                0.5   \n",
       "3979           0.5              0.5                0.5   \n",
       "3980           0.5              0.5                0.5   \n",
       "3981           0.5              0.5                0.5   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                           0.5                                    0.5   \n",
       "1                           0.5                                    0.5   \n",
       "3                           0.5                                    0.5   \n",
       "4                           0.5                                    0.5   \n",
       "6                           0.5                                    0.5   \n",
       "...                         ...                                    ...   \n",
       "3977                        0.5                                    0.5   \n",
       "3978                        0.5                                    0.5   \n",
       "3979                        0.5                                    0.5   \n",
       "3980                        0.5                                    0.5   \n",
       "3981                        0.5                                    0.5   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                 0.5        0.5                         0.5            0.5  \n",
       "1                 0.5        0.5                         0.5            0.5  \n",
       "3                 0.5        0.5                         0.5            0.5  \n",
       "4                 0.5        0.5                         0.5            0.5  \n",
       "6                 0.5        0.5                         0.5            0.5  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977              0.5        0.5                         0.5            0.5  \n",
       "3978              0.5        0.5                         0.5            0.5  \n",
       "3979              0.5        0.5                         0.5            0.5  \n",
       "3980              0.5        0.5                         0.5            0.5  \n",
       "3981              0.5        0.5                         0.5            0.5  \n",
       "\n",
       "[3624 rows x 206 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.loc[~sample_submission['sig_id'].isin(te_ctrl_vehicle_idx),targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:25:08.063874Z",
     "iopub.status.busy": "2020-11-02T01:25:08.062878Z",
     "iopub.status.idle": "2020-11-02T01:25:08.544120Z",
     "shell.execute_reply": "2020-11-02T01:25:08.544702Z"
    },
    "papermill": {
     "duration": 0.604161,
     "end_time": "2020-11-02T01:25:08.544865",
     "exception": false,
     "start_time": "2020-11-02T01:25:07.940704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission.loc[~sample_submission['sig_id'].isin(te_ctrl_vehicle_idx),targets]=prediction\n",
    "sample_submission.loc[sample_submission['sig_id'].isin(te_ctrl_vehicle_idx),targets]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:25:08.777738Z",
     "iopub.status.busy": "2020-11-02T01:25:08.772594Z",
     "iopub.status.idle": "2020-11-02T01:25:08.782847Z",
     "shell.execute_reply": "2020-11-02T01:25:08.783509Z"
    },
    "papermill": {
     "duration": 0.136627,
     "end_time": "2020-11-02T01:25:08.783666",
     "exception": false,
     "start_time": "2020-11-02T01:25:08.647039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.009764</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>0.007064</td>\n",
       "      <td>0.008375</td>\n",
       "      <td>0.007573</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.007684</td>\n",
       "      <td>0.008903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005892</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>0.006718</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>0.007763</td>\n",
       "      <td>0.007806</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>0.007528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.008626</td>\n",
       "      <td>0.007425</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>0.010815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007851</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.009048</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.008359</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>0.007461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.006718</td>\n",
       "      <td>0.007527</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.009837</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>0.011092</td>\n",
       "      <td>0.011460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.009751</td>\n",
       "      <td>0.007742</td>\n",
       "      <td>0.006761</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.008002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>0.007798</td>\n",
       "      <td>0.008127</td>\n",
       "      <td>0.004913</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.005793</td>\n",
       "      <td>0.004846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>0.007983</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.006795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_0004d9e33                     0.009764                0.005168   \n",
       "1  id_001897cda                     0.007417                0.005142   \n",
       "2  id_002429b5b                     0.000000                0.000000   \n",
       "3  id_00276f245                     0.006155                0.005434   \n",
       "4  id_0027f1083                     0.008077                0.007194   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0        0.006733                        0.007064   \n",
       "1        0.006600                        0.006842   \n",
       "2        0.000000                        0.000000   \n",
       "3        0.006718                        0.007527   \n",
       "4        0.007530                        0.007798   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                           0.008375                        0.007573   \n",
       "1                           0.006433                        0.008626   \n",
       "2                           0.000000                        0.000000   \n",
       "3                           0.006836                        0.009837   \n",
       "4                           0.008127                        0.004913   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                    0.008064                       0.007684   \n",
       "1                    0.007425                       0.009621   \n",
       "2                    0.000000                       0.000000   \n",
       "3                    0.009298                       0.011092   \n",
       "4                    0.008016                       0.005793   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                    0.008903  ...                               0.005892   \n",
       "1                    0.010815  ...                               0.007851   \n",
       "2                    0.000000  ...                               0.000000   \n",
       "3                    0.011460  ...                               0.007881   \n",
       "4                    0.004846  ...                               0.006619   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      0.006507         0.006718           0.006838   \n",
       "1      0.004202         0.005006           0.009048   \n",
       "2      0.000000         0.000000           0.000000   \n",
       "3      0.003762         0.004322           0.009751   \n",
       "4      0.004142         0.007421           0.006191   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                   0.007763                               0.007806   \n",
       "1                   0.007143                               0.008359   \n",
       "2                   0.000000                               0.000000   \n",
       "3                   0.007742                               0.006761   \n",
       "4                   0.007983                               0.004431   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0         0.010858   0.006795                    0.006107       0.007528  \n",
       "1         0.008146   0.005189                    0.008678       0.007461  \n",
       "2         0.000000   0.000000                    0.000000       0.000000  \n",
       "3         0.008398   0.006838                    0.007700       0.008002  \n",
       "4         0.005072   0.004485                    0.006682       0.006795  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T01:25:09.008789Z",
     "iopub.status.busy": "2020-11-02T01:25:09.007792Z",
     "iopub.status.idle": "2020-11-02T01:25:11.597230Z",
     "shell.execute_reply": "2020-11-02T01:25:11.598408Z"
    },
    "papermill": {
     "duration": 2.698298,
     "end_time": "2020-11-02T01:25:11.598596",
     "exception": false,
     "start_time": "2020-11-02T01:25:08.900298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 186.086307,
   "end_time": "2020-11-02T01:25:12.803632",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-02T01:22:06.717325",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
